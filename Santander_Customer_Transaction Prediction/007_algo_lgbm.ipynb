{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithms\n",
    "\n",
    "In last section we have got preprocessed dataset, in this section we will use different algorithms to predict the target. The experiment information is shown in following table:\n",
    "\n",
    "|Name|Description|\n",
    "|-----|-----|\n",
    "|Algorithm|logistic regression, SVM, random forest, lightGBM\n",
    "|Metrics|precision, recall, f1, roc_auc|\n",
    "\n",
    "Due to time limit, instead of submitting to kaggle, we just test our performance on validation dataset\n",
    "\n",
    "Some algorithms will not be used\n",
    "\n",
    "|Algorithm|Reason|\n",
    "|-----|\n",
    "|Decision tree|need to discreticize the continuous features|\n",
    "|KNN|computational expensive|\n",
    "|Neural networks|computational expensive|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(train_data_path, train_label_path, val_data_path, val_label_path):\n",
    "    val_data = pd.read_csv(val_data_path)\n",
    "    val_data.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "    val_label = pd.read_csv(val_label_path)\n",
    "    val_label.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "    train_data = pd.read_csv(train_data_path)\n",
    "    train_data.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "    train_data.columns = val_data.columns\n",
    "    train_label = pd.read_csv(train_label_path)\n",
    "    train_label.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "    train_label.columns = val_label.columns\n",
    "    \n",
    "    print(\"Train: {},{}\".format(train_data.shape, train_label.shape))\n",
    "    print(\"Val: {}, {}\".format(val_data.shape, val_label.shape))\n",
    "    \n",
    "    return train_data, train_label, val_data, val_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (172159, 608),(172159, 1)\n",
      "Val: (40000, 608), (40000, 1)\n"
     ]
    }
   ],
   "source": [
    "train_data_path = \"data/train_data_aug.csv\"\n",
    "train_label_path = \"data/train_label_aug.csv\"\n",
    "val_data_path = \"data/val_data.csv\"\n",
    "val_label_path = \"data/val_label.csv\"\n",
    "train_data, train_label, val_data, val_label = load_data(train_data_path, train_label_path, val_data_path, val_label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>...</th>\n",
       "      <th>r1_var_195</th>\n",
       "      <th>r2_var_195</th>\n",
       "      <th>r1_var_196</th>\n",
       "      <th>r2_var_196</th>\n",
       "      <th>r1_var_197</th>\n",
       "      <th>r2_var_197</th>\n",
       "      <th>r1_var_198</th>\n",
       "      <th>r2_var_198</th>\n",
       "      <th>r1_var_199</th>\n",
       "      <th>r2_var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0791</td>\n",
       "      <td>-5.8477</td>\n",
       "      <td>8.8131</td>\n",
       "      <td>4.6344</td>\n",
       "      <td>8.1044</td>\n",
       "      <td>-10.5568</td>\n",
       "      <td>5.0763</td>\n",
       "      <td>14.5844</td>\n",
       "      <td>3.3410</td>\n",
       "      <td>6.1917</td>\n",
       "      <td>...</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.56</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>-2.50</td>\n",
       "      <td>11.3</td>\n",
       "      <td>11.34</td>\n",
       "      <td>16.1</td>\n",
       "      <td>16.12</td>\n",
       "      <td>6.3</td>\n",
       "      <td>6.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.6703</td>\n",
       "      <td>-0.9864</td>\n",
       "      <td>9.4683</td>\n",
       "      <td>5.1137</td>\n",
       "      <td>8.4150</td>\n",
       "      <td>-6.8208</td>\n",
       "      <td>4.9258</td>\n",
       "      <td>18.6177</td>\n",
       "      <td>-2.2627</td>\n",
       "      <td>5.5176</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-0.59</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>-1.06</td>\n",
       "      <td>7.9</td>\n",
       "      <td>7.88</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.39</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.2814</td>\n",
       "      <td>-1.5980</td>\n",
       "      <td>4.8137</td>\n",
       "      <td>7.0230</td>\n",
       "      <td>11.9859</td>\n",
       "      <td>-1.7557</td>\n",
       "      <td>4.3975</td>\n",
       "      <td>20.6678</td>\n",
       "      <td>3.5098</td>\n",
       "      <td>9.0079</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>-1.69</td>\n",
       "      <td>6.1</td>\n",
       "      <td>6.07</td>\n",
       "      <td>10.3</td>\n",
       "      <td>10.27</td>\n",
       "      <td>17.3</td>\n",
       "      <td>17.32</td>\n",
       "      <td>-10.3</td>\n",
       "      <td>-10.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 608 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     var_0   var_1   var_2   var_3    var_4    var_5   var_6    var_7   var_8  \\\n",
       "0  10.0791 -5.8477  8.8131  4.6344   8.1044 -10.5568  5.0763  14.5844  3.3410   \n",
       "1  12.6703 -0.9864  9.4683  5.1137   8.4150  -6.8208  4.9258  18.6177 -2.2627   \n",
       "2  13.2814 -1.5980  4.8137  7.0230  11.9859  -1.7557  4.3975  20.6678  3.5098   \n",
       "\n",
       "    var_9  ...  r1_var_195  r2_var_195  r1_var_196  r2_var_196  r1_var_197  \\\n",
       "0  6.1917  ...         2.6        2.56        -2.5       -2.50        11.3   \n",
       "1  5.5176  ...        -0.6       -0.59        -1.1       -1.06         7.9   \n",
       "2  9.0079  ...        -1.7       -1.69         6.1        6.07        10.3   \n",
       "\n",
       "   r2_var_197  r1_var_198  r2_var_198  r1_var_199  r2_var_199  \n",
       "0       11.34        16.1       16.12         6.3        6.29  \n",
       "1        7.88        19.4       19.39         0.1        0.06  \n",
       "2       10.27        17.3       17.32       -10.3      -10.33  \n",
       "\n",
       "[3 rows x 608 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_label = train_label.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target\n",
      "0    107963\n",
      "1     64196\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target\n",
       "0       0\n",
       "1       0\n",
       "2       0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_label.groupby('target').size())\n",
    "train_label.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target\n",
      "0    35951\n",
      "1     4049\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target\n",
       "0       0\n",
       "1       0\n",
       "2       0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(val_label.groupby('target').size())\n",
    "val_label.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_lgbm(param, train_data, train_label, val_data, val_label):\n",
    "    print(\"===== Build dataset for lgbm\")\n",
    "    lgbm_train_data = lgb.Dataset(train_data, label=train_label)\n",
    "    lgbm_val_data = lgb.Dataset(val_data, label=val_label)\n",
    "    \n",
    "    print(\"===== Start training\")\n",
    "    start_time = time()\n",
    "    clf = lgb.train(param, \n",
    "                    lgbm_train_data, \n",
    "                    1000000, \n",
    "                    valid_sets = [lgbm_train_data, lgbm_val_data], \n",
    "                    verbose_eval = 1000, \n",
    "                    early_stopping_rounds = 3000)\n",
    "    training_time = (time() - start_time) / 60.\n",
    "    print(\"===== Training time: {:.2f}min\".format(training_time))\n",
    "    \n",
    "    # compute auroc\n",
    "    print(\"===== Get prediction\")\n",
    "    pred_tr = clf.predict(train_data, num_iteration=clf.best_iteration)\n",
    "    pred_cv = clf.predict(val_data, num_iteration=clf.best_iteration)\n",
    "    # get metrics\n",
    "    print(\"===== Build metrics\")\n",
    "    train_label, val_label = np.ravel(train_label), np.ravel(val_label)\n",
    "    a_tr = roc_auc_score(train_label, pred_tr)\n",
    "    a_cv = roc_auc_score(val_label, pred_cv)\n",
    "    progress = \"auroc|train {:.4f}|val {:.4f}\".format(a_tr, a_cv)\n",
    "    print(\"Final result\")\n",
    "    print(progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.967496\tvalid_1's auc: 0.865195\n",
      "[2000]\ttraining's auc: 0.9744\tvalid_1's auc: 0.885277\n",
      "[3000]\ttraining's auc: 0.977985\tvalid_1's auc: 0.894038\n",
      "[4000]\ttraining's auc: 0.980366\tvalid_1's auc: 0.898738\n",
      "[5000]\ttraining's auc: 0.982165\tvalid_1's auc: 0.900716\n",
      "[6000]\ttraining's auc: 0.983676\tvalid_1's auc: 0.901769\n",
      "[7000]\ttraining's auc: 0.985035\tvalid_1's auc: 0.901904\n",
      "[8000]\ttraining's auc: 0.986303\tvalid_1's auc: 0.902023\n",
      "[9000]\ttraining's auc: 0.987514\tvalid_1's auc: 0.90209\n",
      "[10000]\ttraining's auc: 0.988661\tvalid_1's auc: 0.901965\n",
      "[11000]\ttraining's auc: 0.989754\tvalid_1's auc: 0.901906\n",
      "[12000]\ttraining's auc: 0.990765\tvalid_1's auc: 0.901767\n",
      "Early stopping, best iteration is:\n",
      "[9031]\ttraining's auc: 0.987549\tvalid_1's auc: 0.902114\n",
      "===== Training time: 2.09min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9875|val 0.9021\n"
     ]
    }
   ],
   "source": [
    "param = {\n",
    "    'bagging_freq': 5,\n",
    "    'bagging_fraction': 0.4,\n",
    "    'boost_from_average':'false',\n",
    "    'boost': 'gbdt',\n",
    "    'feature_fraction': 0.05,\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': -1,  \n",
    "    'metric':'auc',\n",
    "    'min_data_in_leaf': 80,\n",
    "    'min_sum_hessian_in_leaf': 10.0,\n",
    "    'num_leaves': 13,\n",
    "    'num_threads': 22,\n",
    "    'tree_learner': 'serial',\n",
    "    'objective': 'binary', \n",
    "    'verbosity': 1\n",
    "}\n",
    "train_lgbm(param, train_data, train_label, val_data, val_label)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "    'bagging_freq': 5,\n",
    "    'bagging_fraction': 0.4,\n",
    "    'boost_from_average':'false',\n",
    "    'boost': 'gbdt',\n",
    "    'feature_fraction': 0.05,\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': -1,  \n",
    "    'min_data_in_leaf': 80,\n",
    "    'min_sum_hessian_in_leaf': 10.0,\n",
    "    'num_leaves': 13,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LGBM round 1, seems overfitting\n",
    "param = {\n",
    "    'boosting_type': 'gbdt', \n",
    "    'objective': 'binary', \n",
    "    'tree_learner': 'serial', \n",
    "    'verbosity': 1,\n",
    "    'learning_rate': 0.1, \n",
    "    'num_threads': 22,\n",
    "    'metric':'auc',\n",
    "    \n",
    "    'num_leaves': 15, \n",
    "    'max_depth': -1,\n",
    "    }\n",
    "# train_lgbm(param, train_data, train_label, val_data, val_label)\n",
    "\n",
    "# [1000]\ttraining's auc: 0.996931\tvalid_1's auc: 0.893899\n",
    "# [2000]\ttraining's auc: 0.99992\tvalid_1's auc: 0.892059"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth: 3\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.987355\tvalid_1's auc: 0.895526\n",
      "[2000]\ttraining's auc: 0.993022\tvalid_1's auc: 0.896852\n",
      "[3000]\ttraining's auc: 0.99625\tvalid_1's auc: 0.894902\n",
      "[4000]\ttraining's auc: 0.998186\tvalid_1's auc: 0.89313\n",
      "Early stopping, best iteration is:\n",
      "[1891]\ttraining's auc: 0.992566\tvalid_1's auc: 0.897038\n",
      "===== Training time: 1.84min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9926|val 0.8970\n",
      "===========\n",
      "max_depth: 5\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.996023\tvalid_1's auc: 0.891726\n",
      "[2000]\ttraining's auc: 0.999684\tvalid_1's auc: 0.890093\n",
      "[3000]\ttraining's auc: 0.99999\tvalid_1's auc: 0.88843\n",
      "Early stopping, best iteration is:\n",
      "[813]\ttraining's auc: 0.994059\tvalid_1's auc: 0.892079\n",
      "===== Training time: 1.62min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9941|val 0.8921\n",
      "===========\n",
      "max_depth: 7\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.996779\tvalid_1's auc: 0.894374\n",
      "[2000]\ttraining's auc: 0.999889\tvalid_1's auc: 0.89192\n",
      "[3000]\ttraining's auc: 1\tvalid_1's auc: 0.890956\n",
      "Early stopping, best iteration is:\n",
      "[852]\ttraining's auc: 0.995329\tvalid_1's auc: 0.894731\n",
      "===== Training time: 1.66min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9953|val 0.8947\n",
      "===========\n",
      "max_depth: 9\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.996887\tvalid_1's auc: 0.894891\n",
      "[2000]\ttraining's auc: 0.999894\tvalid_1's auc: 0.89195\n",
      "[3000]\ttraining's auc: 1\tvalid_1's auc: 0.890493\n",
      "Early stopping, best iteration is:\n",
      "[531]\ttraining's auc: 0.990027\tvalid_1's auc: 0.895919\n",
      "===== Training time: 1.58min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9900|val 0.8959\n",
      "===========\n",
      "max_depth: 11\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.996932\tvalid_1's auc: 0.893273\n",
      "[2000]\ttraining's auc: 0.999917\tvalid_1's auc: 0.890666\n",
      "[3000]\ttraining's auc: 1\tvalid_1's auc: 0.889071\n",
      "Early stopping, best iteration is:\n",
      "[570]\ttraining's auc: 0.990916\tvalid_1's auc: 0.894673\n",
      "===== Training time: 1.61min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9909|val 0.8947\n",
      "===========\n",
      "max_depth: 13\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.996952\tvalid_1's auc: 0.893558\n",
      "[2000]\ttraining's auc: 0.999905\tvalid_1's auc: 0.892082\n",
      "[3000]\ttraining's auc: 1\tvalid_1's auc: 0.890964\n",
      "Early stopping, best iteration is:\n",
      "[637]\ttraining's auc: 0.99217\tvalid_1's auc: 0.894397\n",
      "===== Training time: 1.61min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9922|val 0.8944\n",
      "===========\n",
      "max_depth: 15\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.996931\tvalid_1's auc: 0.893899\n",
      "[2000]\ttraining's auc: 0.99992\tvalid_1's auc: 0.892059\n",
      "[3000]\ttraining's auc: 1\tvalid_1's auc: 0.891054\n",
      "Early stopping, best iteration is:\n",
      "[635]\ttraining's auc: 0.992148\tvalid_1's auc: 0.894558\n",
      "===== Training time: 1.62min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9921|val 0.8946\n",
      "===========\n"
     ]
    }
   ],
   "source": [
    "# LGBM round 2: max depth = 15\n",
    "param_base = {\n",
    "    'boosting_type': 'gbdt', \n",
    "    'objective': 'binary', \n",
    "    'tree_learner': 'serial', \n",
    "    'verbosity': 1,\n",
    "    'learning_rate': 0.1, # smaller later \n",
    "    'num_threads': 22,\n",
    "    'metric':'auc',\n",
    "    \n",
    "    'num_leaves': 15, \n",
    "    'max_depth': -1,\n",
    "    }\n",
    "param_list = range(3,16,2)\n",
    "for curr_param in param_list:\n",
    "    print(\"max_depth: {}\".format(curr_param))\n",
    "    param_base['max_depth'] = curr_param\n",
    "    train_lgbm(param_base, train_data, train_label, val_data, val_label)\n",
    "    print(\"===========\")\n",
    "    \n",
    "# train 0.9921|val 0.8946"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth: 17\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.996931\tvalid_1's auc: 0.893899\n",
      "[2000]\ttraining's auc: 0.99992\tvalid_1's auc: 0.892059\n",
      "[3000]\ttraining's auc: 1\tvalid_1's auc: 0.891054\n",
      "Early stopping, best iteration is:\n",
      "[635]\ttraining's auc: 0.992148\tvalid_1's auc: 0.894558\n",
      "===== Training time: 1.73min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9921|val 0.8946\n",
      "===========\n",
      "max_depth: 19\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.996931\tvalid_1's auc: 0.893899\n",
      "[2000]\ttraining's auc: 0.99992\tvalid_1's auc: 0.892059\n",
      "[3000]\ttraining's auc: 1\tvalid_1's auc: 0.891054\n",
      "Early stopping, best iteration is:\n",
      "[635]\ttraining's auc: 0.992148\tvalid_1's auc: 0.894558\n",
      "===== Training time: 1.71min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9921|val 0.8946\n",
      "===========\n",
      "max_depth: 21\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.996931\tvalid_1's auc: 0.893899\n",
      "[2000]\ttraining's auc: 0.99992\tvalid_1's auc: 0.892059\n",
      "[3000]\ttraining's auc: 1\tvalid_1's auc: 0.891054\n",
      "Early stopping, best iteration is:\n",
      "[635]\ttraining's auc: 0.992148\tvalid_1's auc: 0.894558\n",
      "===== Training time: 1.69min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9921|val 0.8946\n",
      "===========\n",
      "max_depth: 23\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.996931\tvalid_1's auc: 0.893899\n",
      "[2000]\ttraining's auc: 0.99992\tvalid_1's auc: 0.892059\n",
      "[3000]\ttraining's auc: 1\tvalid_1's auc: 0.891054\n",
      "Early stopping, best iteration is:\n",
      "[635]\ttraining's auc: 0.992148\tvalid_1's auc: 0.894558\n",
      "===== Training time: 1.65min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9921|val 0.8946\n",
      "===========\n",
      "max_depth: 25\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-303d0fcd1a99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"max_depth: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_param\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mparam_base\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'max_depth'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurr_param\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mtrain_lgbm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_base\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"===========\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-0314a31fa762>\u001b[0m in \u001b[0;36mtrain_lgbm\u001b[0;34m(param, train_data, train_label, val_data, val_label)\u001b[0m\n\u001b[1;32m     11\u001b[0m                     \u001b[0mvalid_sets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlgbm_train_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlgbm_val_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                     \u001b[0mverbose_eval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                     early_stopping_rounds = 3000)\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mtraining_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m60.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"===== Training time: {:.2f}min\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    216\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   1800\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   1801\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1802\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   1803\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1804\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# LGBM round 3: max depth ranges from 17 to 25\n",
    "# But the performance will not change\n",
    "param_base = {\n",
    "    'boosting_type': 'gbdt', \n",
    "    'objective': 'binary', \n",
    "    'tree_learner': 'serial', \n",
    "    'verbosity': 1,\n",
    "    'learning_rate': 0.1, # smaller later \n",
    "    'num_threads': 22,\n",
    "    'metric':'auc',\n",
    "    \n",
    "    'num_leaves': 15, \n",
    "    'max_depth': -1,\n",
    "    }\n",
    "param_list = range(17,26,2)\n",
    "for curr_param in param_list:\n",
    "    print(\"max_depth: {}\".format(curr_param))\n",
    "    param_base['max_depth'] = curr_param\n",
    "    train_lgbm(param_base, train_data, train_label, val_data, val_label)\n",
    "    print(\"===========\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_leaves: 5\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.982036\tvalid_1's auc: 0.897806\n",
      "[2000]\ttraining's auc: 0.98875\tvalid_1's auc: 0.897783\n",
      "[3000]\ttraining's auc: 0.992822\tvalid_1's auc: 0.897007\n",
      "[4000]\ttraining's auc: 0.995527\tvalid_1's auc: 0.896069\n",
      "Early stopping, best iteration is:\n",
      "[1538]\ttraining's auc: 0.986005\tvalid_1's auc: 0.898442\n",
      "===== Training time: 1.60min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9860|val 0.8984\n",
      "===========\n",
      "num_leaves: 7\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.986802\tvalid_1's auc: 0.896958\n",
      "[2000]\ttraining's auc: 0.994286\tvalid_1's auc: 0.896658\n",
      "[3000]\ttraining's auc: 0.997716\tvalid_1's auc: 0.895635\n",
      "[4000]\ttraining's auc: 0.999223\tvalid_1's auc: 0.894608\n",
      "Early stopping, best iteration is:\n",
      "[1316]\ttraining's auc: 0.989787\tvalid_1's auc: 0.897596\n",
      "===== Training time: 1.59min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9898|val 0.8976\n",
      "===========\n",
      "num_leaves: 9\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.990362\tvalid_1's auc: 0.896116\n",
      "[2000]\ttraining's auc: 0.997355\tvalid_1's auc: 0.895472\n",
      "[3000]\ttraining's auc: 0.999438\tvalid_1's auc: 0.893937\n",
      "[4000]\ttraining's auc: 0.999937\tvalid_1's auc: 0.892353\n",
      "Early stopping, best iteration is:\n",
      "[1250]\ttraining's auc: 0.992918\tvalid_1's auc: 0.896294\n",
      "===== Training time: 1.64min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9929|val 0.8963\n",
      "===========\n",
      "num_leaves: 11\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.993243\tvalid_1's auc: 0.895201\n",
      "[2000]\ttraining's auc: 0.998971\tvalid_1's auc: 0.893386\n",
      "[3000]\ttraining's auc: 0.999932\tvalid_1's auc: 0.891796\n",
      "Early stopping, best iteration is:\n",
      "[994]\ttraining's auc: 0.993182\tvalid_1's auc: 0.895291\n",
      "===== Training time: 1.64min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9932|val 0.8953\n",
      "===========\n",
      "num_leaves: 13\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.995419\tvalid_1's auc: 0.893732\n",
      "[2000]\ttraining's auc: 0.99967\tvalid_1's auc: 0.892351\n",
      "[3000]\ttraining's auc: 0.999997\tvalid_1's auc: 0.890098\n",
      "Early stopping, best iteration is:\n",
      "[686]\ttraining's auc: 0.991204\tvalid_1's auc: 0.894141\n",
      "===== Training time: 1.66min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9912|val 0.8941\n",
      "===========\n",
      "num_leaves: 15\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.996931\tvalid_1's auc: 0.893899\n",
      "[2000]\ttraining's auc: 0.99992\tvalid_1's auc: 0.892059\n",
      "[3000]\ttraining's auc: 1\tvalid_1's auc: 0.891054\n",
      "Early stopping, best iteration is:\n",
      "[635]\ttraining's auc: 0.992148\tvalid_1's auc: 0.894558\n",
      "===== Training time: 1.75min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9921|val 0.8946\n",
      "===========\n"
     ]
    }
   ],
   "source": [
    "# LGBM round 4: num_leaves -> 5\n",
    "param_base = {\n",
    "    'boosting_type': 'gbdt', \n",
    "    'objective': 'binary', \n",
    "    'tree_learner': 'serial', \n",
    "    'verbosity': 1,\n",
    "    'learning_rate': 0.1, # smaller later \n",
    "    'num_threads': 22,\n",
    "    'metric':'auc',\n",
    "    \n",
    "    'num_leaves': 15, \n",
    "    'max_depth': 15,\n",
    "    }\n",
    "param_list = range(5,16,2)\n",
    "for curr_param in param_list:\n",
    "    print(\"num_leaves: {}\".format(curr_param))\n",
    "    param_base['num_leaves'] = curr_param\n",
    "    train_lgbm(param_base, train_data, train_label, val_data, val_label)\n",
    "    print(\"===========\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf: 50\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.981822\tvalid_1's auc: 0.898178\n",
      "[2000]\ttraining's auc: 0.987556\tvalid_1's auc: 0.898728\n",
      "[3000]\ttraining's auc: 0.991369\tvalid_1's auc: 0.897917\n",
      "[4000]\ttraining's auc: 0.994144\tvalid_1's auc: 0.896635\n",
      "Early stopping, best iteration is:\n",
      "[1626]\ttraining's auc: 0.985716\tvalid_1's auc: 0.899024\n",
      "===== Training time: 1.59min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9857|val 0.8990\n",
      "===========\n",
      "min_data_in_leaf: 60\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.981822\tvalid_1's auc: 0.898178\n",
      "[2000]\ttraining's auc: 0.987556\tvalid_1's auc: 0.898728\n",
      "[3000]\ttraining's auc: 0.991369\tvalid_1's auc: 0.897917\n",
      "[4000]\ttraining's auc: 0.994144\tvalid_1's auc: 0.896635\n",
      "Early stopping, best iteration is:\n",
      "[1626]\ttraining's auc: 0.985716\tvalid_1's auc: 0.899024\n",
      "===== Training time: 1.56min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9857|val 0.8990\n",
      "===========\n",
      "min_data_in_leaf: 70\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.981822\tvalid_1's auc: 0.898178\n",
      "[2000]\ttraining's auc: 0.987556\tvalid_1's auc: 0.898728\n",
      "[3000]\ttraining's auc: 0.991369\tvalid_1's auc: 0.897917\n",
      "[4000]\ttraining's auc: 0.994144\tvalid_1's auc: 0.896635\n",
      "Early stopping, best iteration is:\n",
      "[1626]\ttraining's auc: 0.985716\tvalid_1's auc: 0.899024\n",
      "===== Training time: 1.52min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9857|val 0.8990\n",
      "===========\n",
      "min_data_in_leaf: 80\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.981822\tvalid_1's auc: 0.898178\n",
      "[2000]\ttraining's auc: 0.987556\tvalid_1's auc: 0.898728\n",
      "[3000]\ttraining's auc: 0.991369\tvalid_1's auc: 0.897917\n",
      "[4000]\ttraining's auc: 0.994144\tvalid_1's auc: 0.896635\n",
      "Early stopping, best iteration is:\n",
      "[1626]\ttraining's auc: 0.985716\tvalid_1's auc: 0.899024\n",
      "===== Training time: 1.54min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9857|val 0.8990\n",
      "===========\n",
      "min_data_in_leaf: 90\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.981822\tvalid_1's auc: 0.898178\n",
      "[2000]\ttraining's auc: 0.987556\tvalid_1's auc: 0.898728\n",
      "[3000]\ttraining's auc: 0.991369\tvalid_1's auc: 0.897917\n",
      "[4000]\ttraining's auc: 0.994144\tvalid_1's auc: 0.896635\n",
      "Early stopping, best iteration is:\n",
      "[1626]\ttraining's auc: 0.985716\tvalid_1's auc: 0.899024\n",
      "===== Training time: 1.53min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9857|val 0.8990\n",
      "===========\n",
      "min_data_in_leaf: 100\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.981822\tvalid_1's auc: 0.898178\n",
      "[2000]\ttraining's auc: 0.987556\tvalid_1's auc: 0.898728\n",
      "[3000]\ttraining's auc: 0.991369\tvalid_1's auc: 0.897917\n",
      "[4000]\ttraining's auc: 0.994144\tvalid_1's auc: 0.896635\n",
      "Early stopping, best iteration is:\n",
      "[1626]\ttraining's auc: 0.985716\tvalid_1's auc: 0.899024\n",
      "===== Training time: 1.53min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9857|val 0.8990\n",
      "===========\n",
      "min_data_in_leaf: 110\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.981822\tvalid_1's auc: 0.898178\n",
      "[2000]\ttraining's auc: 0.987556\tvalid_1's auc: 0.898728\n",
      "[3000]\ttraining's auc: 0.991369\tvalid_1's auc: 0.897917\n",
      "[4000]\ttraining's auc: 0.994144\tvalid_1's auc: 0.896635\n",
      "Early stopping, best iteration is:\n",
      "[1626]\ttraining's auc: 0.985716\tvalid_1's auc: 0.899024\n",
      "===== Training time: 1.53min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9857|val 0.8990\n",
      "===========\n",
      "min_data_in_leaf: 120\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.981822\tvalid_1's auc: 0.898178\n",
      "[2000]\ttraining's auc: 0.98755\tvalid_1's auc: 0.898959\n",
      "[3000]\ttraining's auc: 0.991388\tvalid_1's auc: 0.897982\n",
      "[4000]\ttraining's auc: 0.99415\tvalid_1's auc: 0.897539\n",
      "Early stopping, best iteration is:\n",
      "[1675]\ttraining's auc: 0.98599\tvalid_1's auc: 0.899245\n",
      "===== Training time: 1.57min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9860|val 0.8992\n",
      "===========\n",
      "min_data_in_leaf: 130\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.981822\tvalid_1's auc: 0.898178\n",
      "[2000]\ttraining's auc: 0.987529\tvalid_1's auc: 0.898502\n",
      "[3000]\ttraining's auc: 0.991364\tvalid_1's auc: 0.897795\n",
      "[4000]\ttraining's auc: 0.994145\tvalid_1's auc: 0.896471\n",
      "Early stopping, best iteration is:\n",
      "[1294]\ttraining's auc: 0.983802\tvalid_1's auc: 0.899013\n",
      "===== Training time: 1.50min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9838|val 0.8990\n",
      "===========\n",
      "min_data_in_leaf: 140\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.981822\tvalid_1's auc: 0.898178\n",
      "[2000]\ttraining's auc: 0.987571\tvalid_1's auc: 0.898953\n",
      "[3000]\ttraining's auc: 0.991405\tvalid_1's auc: 0.897884\n",
      "[4000]\ttraining's auc: 0.994137\tvalid_1's auc: 0.896942\n",
      "Early stopping, best iteration is:\n",
      "[1251]\ttraining's auc: 0.983536\tvalid_1's auc: 0.899096\n",
      "===== Training time: 1.44min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9835|val 0.8991\n",
      "===========\n",
      "min_data_in_leaf: 150\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.981814\tvalid_1's auc: 0.898106\n",
      "[2000]\ttraining's auc: 0.98752\tvalid_1's auc: 0.898661\n",
      "[3000]\ttraining's auc: 0.99132\tvalid_1's auc: 0.897865\n",
      "[4000]\ttraining's auc: 0.994114\tvalid_1's auc: 0.897083\n",
      "Early stopping, best iteration is:\n",
      "[1686]\ttraining's auc: 0.985967\tvalid_1's auc: 0.89927\n",
      "===== Training time: 1.57min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9860|val 0.8993\n",
      "===========\n"
     ]
    }
   ],
   "source": [
    "# LGBM round 5: min_data_in leaf --> 120\n",
    "param_base = {\n",
    "    'boosting_type': 'gbdt', \n",
    "    'boost_from_average': False, \n",
    "    'objective': 'binary', \n",
    "    'tree_learner': 'serial', \n",
    "    'verbosity': 1,\n",
    "    'learning_rate': 0.1, # smaller later \n",
    "    'num_threads': 22,\n",
    "    'metric':'auc',\n",
    "    \n",
    "    'num_leaves': 5, \n",
    "    'max_depth': 15,\n",
    "    'min_data_in_leaf': 120,\n",
    "    'min_sum_hessian_in_leaf': 10\n",
    "    }\n",
    "param_list = range(50,151,10)\n",
    "for curr_param in param_list:\n",
    "    print(\"min_data_in_leaf: {}\".format(curr_param))\n",
    "    param_base['min_data_in_leaf'] = curr_param\n",
    "    train_lgbm(param_base, train_data, train_label, val_data, val_label)\n",
    "    print(\"===========\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bagging_freq: 1\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.978532\tvalid_1's auc: 0.89872\n",
      "[2000]\ttraining's auc: 0.982814\tvalid_1's auc: 0.899432\n",
      "[3000]\ttraining's auc: 0.986379\tvalid_1's auc: 0.896501\n",
      "[4000]\ttraining's auc: 0.989274\tvalid_1's auc: 0.894899\n",
      "Early stopping, best iteration is:\n",
      "[1591]\ttraining's auc: 0.981213\tvalid_1's auc: 0.900466\n",
      "===== Training time: 0.84min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9812|val 0.9005\n",
      "===========\n",
      "bagging_freq: 3\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.97855\tvalid_1's auc: 0.898497\n",
      "[2000]\ttraining's auc: 0.982863\tvalid_1's auc: 0.899571\n",
      "[3000]\ttraining's auc: 0.986376\tvalid_1's auc: 0.89669\n",
      "[4000]\ttraining's auc: 0.989295\tvalid_1's auc: 0.893794\n",
      "Early stopping, best iteration is:\n",
      "[1442]\ttraining's auc: 0.98059\tvalid_1's auc: 0.900408\n",
      "===== Training time: 0.69min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9806|val 0.9004\n",
      "===========\n",
      "bagging_freq: 5\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.9786\tvalid_1's auc: 0.898946\n",
      "[2000]\ttraining's auc: 0.982873\tvalid_1's auc: 0.898775\n",
      "[3000]\ttraining's auc: 0.986452\tvalid_1's auc: 0.896836\n",
      "[4000]\ttraining's auc: 0.989467\tvalid_1's auc: 0.894925\n",
      "Early stopping, best iteration is:\n",
      "[1519]\ttraining's auc: 0.980912\tvalid_1's auc: 0.899865\n",
      "===== Training time: 0.68min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9809|val 0.8999\n",
      "===========\n",
      "bagging_freq: 7\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.978525\tvalid_1's auc: 0.899238\n",
      "[2000]\ttraining's auc: 0.982862\tvalid_1's auc: 0.898726\n",
      "[3000]\ttraining's auc: 0.986421\tvalid_1's auc: 0.896598\n",
      "[4000]\ttraining's auc: 0.989317\tvalid_1's auc: 0.893633\n",
      "Early stopping, best iteration is:\n",
      "[1599]\ttraining's auc: 0.981276\tvalid_1's auc: 0.900196\n",
      "===== Training time: 0.68min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9813|val 0.9002\n",
      "===========\n",
      "bagging_freq: 9\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.978549\tvalid_1's auc: 0.89858\n",
      "[2000]\ttraining's auc: 0.982729\tvalid_1's auc: 0.899604\n",
      "[3000]\ttraining's auc: 0.986221\tvalid_1's auc: 0.897183\n",
      "[4000]\ttraining's auc: 0.989221\tvalid_1's auc: 0.89509\n",
      "Early stopping, best iteration is:\n",
      "[1255]\ttraining's auc: 0.979794\tvalid_1's auc: 0.900064\n",
      "===== Training time: 0.66min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9798|val 0.9001\n",
      "===========\n"
     ]
    }
   ],
   "source": [
    "# LGBM round 6: bagging_freq = 1\n",
    "param_base = {\n",
    "    'boosting_type': 'gbdt', \n",
    "    'boost_from_average': False, \n",
    "    'objective': 'binary', \n",
    "    'tree_learner': 'serial', \n",
    "    'verbosity': 1,\n",
    "    'learning_rate': 0.1, # smaller later \n",
    "    'num_threads': 22,\n",
    "    'metric':'auc',\n",
    "    \n",
    "    'num_leaves': 5, \n",
    "    'max_depth': 15,\n",
    "    'min_data_in_leaf': 150,\n",
    "    'min_sum_hessian_in_leaf': 10,\n",
    "    \n",
    "    'bagging_freq': 5,\n",
    "    'bagging_fraction': 0.4,\n",
    "    'feature_fraction': 0.05\n",
    "    }\n",
    "param_list = range(1,10,2)\n",
    "for curr_param in param_list:\n",
    "    print(\"bagging_freq: {}\".format(curr_param))\n",
    "    param_base['bagging_freq'] = curr_param\n",
    "    train_lgbm(param_base, train_data, train_label, val_data, val_label)\n",
    "    print(\"===========\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bagging_fraction: 0.1\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.977545\tvalid_1's auc: 0.896133\n",
      "[2000]\ttraining's auc: 0.98026\tvalid_1's auc: 0.891286\n",
      "[3000]\ttraining's auc: 0.982414\tvalid_1's auc: 0.885124\n",
      "Early stopping, best iteration is:\n",
      "[790]\ttraining's auc: 0.976635\tvalid_1's auc: 0.897013\n",
      "===== Training time: 0.67min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9766|val 0.8970\n",
      "===========\n",
      "bagging_fraction: 0.15\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.978083\tvalid_1's auc: 0.898306\n",
      "[2000]\ttraining's auc: 0.981378\tvalid_1's auc: 0.89416\n",
      "[3000]\ttraining's auc: 0.984141\tvalid_1's auc: 0.890239\n",
      "Early stopping, best iteration is:\n",
      "[864]\ttraining's auc: 0.977468\tvalid_1's auc: 0.898369\n",
      "===== Training time: 0.68min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9775|val 0.8984\n",
      "===========\n",
      "bagging_fraction: 0.2\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.978389\tvalid_1's auc: 0.898159\n",
      "[2000]\ttraining's auc: 0.982129\tvalid_1's auc: 0.896129\n",
      "[3000]\ttraining's auc: 0.985128\tvalid_1's auc: 0.892907\n",
      "[4000]\ttraining's auc: 0.987585\tvalid_1's auc: 0.890758\n",
      "Early stopping, best iteration is:\n",
      "[1135]\ttraining's auc: 0.978957\tvalid_1's auc: 0.898762\n",
      "===== Training time: 0.74min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9790|val 0.8988\n",
      "===========\n",
      "bagging_fraction: 0.25\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.978465\tvalid_1's auc: 0.897947\n",
      "[2000]\ttraining's auc: 0.982365\tvalid_1's auc: 0.896612\n",
      "[3000]\ttraining's auc: 0.985553\tvalid_1's auc: 0.893652\n",
      "[4000]\ttraining's auc: 0.988266\tvalid_1's auc: 0.890806\n",
      "Early stopping, best iteration is:\n",
      "[1133]\ttraining's auc: 0.979055\tvalid_1's auc: 0.898502\n",
      "===== Training time: 0.77min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9791|val 0.8985\n",
      "===========\n",
      "bagging_fraction: 0.3\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.978419\tvalid_1's auc: 0.898343\n",
      "[2000]\ttraining's auc: 0.98246\tvalid_1's auc: 0.898124\n",
      "[3000]\ttraining's auc: 0.985754\tvalid_1's auc: 0.894294\n",
      "[4000]\ttraining's auc: 0.988622\tvalid_1's auc: 0.891462\n",
      "Early stopping, best iteration is:\n",
      "[1512]\ttraining's auc: 0.980655\tvalid_1's auc: 0.89931\n",
      "===== Training time: 0.79min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9807|val 0.8993\n",
      "===========\n",
      "bagging_fraction: 0.35\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.978494\tvalid_1's auc: 0.898137\n",
      "[2000]\ttraining's auc: 0.982631\tvalid_1's auc: 0.899084\n",
      "[3000]\ttraining's auc: 0.986017\tvalid_1's auc: 0.895948\n",
      "[4000]\ttraining's auc: 0.988944\tvalid_1's auc: 0.894145\n",
      "Early stopping, best iteration is:\n",
      "[1491]\ttraining's auc: 0.980726\tvalid_1's auc: 0.900157\n",
      "===== Training time: 0.81min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9807|val 0.9002\n",
      "===========\n",
      "bagging_fraction: 0.4\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.978532\tvalid_1's auc: 0.89872\n",
      "[2000]\ttraining's auc: 0.982814\tvalid_1's auc: 0.899432\n",
      "[3000]\ttraining's auc: 0.986379\tvalid_1's auc: 0.896501\n",
      "[4000]\ttraining's auc: 0.989274\tvalid_1's auc: 0.894899\n",
      "Early stopping, best iteration is:\n",
      "[1591]\ttraining's auc: 0.981213\tvalid_1's auc: 0.900466\n",
      "===== Training time: 0.84min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9812|val 0.9005\n",
      "===========\n",
      "bagging_fraction: 0.45\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.978654\tvalid_1's auc: 0.898896\n",
      "[2000]\ttraining's auc: 0.983058\tvalid_1's auc: 0.898876\n",
      "[3000]\ttraining's auc: 0.986542\tvalid_1's auc: 0.896575\n",
      "[4000]\ttraining's auc: 0.989557\tvalid_1's auc: 0.895034\n",
      "Early stopping, best iteration is:\n",
      "[1329]\ttraining's auc: 0.980254\tvalid_1's auc: 0.899706\n",
      "===== Training time: 0.78min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9803|val 0.8997\n",
      "===========\n",
      "bagging_fraction: 0.5\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.978719\tvalid_1's auc: 0.899297\n",
      "[2000]\ttraining's auc: 0.983135\tvalid_1's auc: 0.899731\n",
      "[3000]\ttraining's auc: 0.986788\tvalid_1's auc: 0.897655\n",
      "[4000]\ttraining's auc: 0.989788\tvalid_1's auc: 0.896282\n",
      "Early stopping, best iteration is:\n",
      "[1595]\ttraining's auc: 0.981494\tvalid_1's auc: 0.900772\n",
      "===== Training time: 0.89min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9815|val 0.9008\n",
      "===========\n",
      "bagging_fraction: 0.55\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.978668\tvalid_1's auc: 0.898879\n",
      "[2000]\ttraining's auc: 0.98325\tvalid_1's auc: 0.899864\n",
      "[3000]\ttraining's auc: 0.986873\tvalid_1's auc: 0.898273\n",
      "[4000]\ttraining's auc: 0.989937\tvalid_1's auc: 0.897218\n",
      "Early stopping, best iteration is:\n",
      "[1340]\ttraining's auc: 0.980368\tvalid_1's auc: 0.900437\n",
      "===== Training time: 0.66min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9804|val 0.9004\n",
      "===========\n",
      "bagging_fraction: 0.6\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.978803\tvalid_1's auc: 0.8992\n",
      "[2000]\ttraining's auc: 0.983269\tvalid_1's auc: 0.90135\n",
      "[3000]\ttraining's auc: 0.986954\tvalid_1's auc: 0.899709\n",
      "[4000]\ttraining's auc: 0.989994\tvalid_1's auc: 0.897423\n",
      "Early stopping, best iteration is:\n",
      "[1748]\ttraining's auc: 0.982256\tvalid_1's auc: 0.901476\n",
      "===== Training time: 0.72min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9823|val 0.9015\n",
      "===========\n"
     ]
    }
   ],
   "source": [
    "# LGBM round 6: bagging_fraction = 0.6\n",
    "param_base = {\n",
    "    'boosting_type': 'gbdt', \n",
    "    'boost_from_average': False, \n",
    "    'objective': 'binary', \n",
    "    'tree_learner': 'serial', \n",
    "    'verbosity': 1,\n",
    "    'learning_rate': 0.1, # smaller later \n",
    "    'num_threads': 22,\n",
    "    'metric':'auc',\n",
    "    \n",
    "    'num_leaves': 5, \n",
    "    'max_depth': 15,\n",
    "    'min_data_in_leaf': 150,\n",
    "    'min_sum_hessian_in_leaf': 10,\n",
    "    \n",
    "    'bagging_freq': 1,\n",
    "    'bagging_fraction': 0.4,\n",
    "    'feature_fraction': 0.05\n",
    "    }\n",
    "param_list = [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6]\n",
    "for curr_param in param_list:\n",
    "    print(\"bagging_fraction: {}\".format(curr_param))\n",
    "    param_base['bagging_fraction'] = curr_param\n",
    "    train_lgbm(param_base, train_data, train_label, val_data, val_label)\n",
    "    print(\"===========\")\n",
    "    \n",
    "# auroc|train 0.9823|val 0.9015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bagging_fraction: 0.65\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.978805\tvalid_1's auc: 0.898715\n",
      "[2000]\ttraining's auc: 0.98328\tvalid_1's auc: 0.9008\n",
      "[3000]\ttraining's auc: 0.986955\tvalid_1's auc: 0.899824\n",
      "[4000]\ttraining's auc: 0.990037\tvalid_1's auc: 0.89851\n",
      "Early stopping, best iteration is:\n",
      "[1706]\ttraining's auc: 0.982026\tvalid_1's auc: 0.901172\n",
      "===== Training time: 0.70min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9820|val 0.9012\n",
      "===========\n",
      "bagging_fraction: 0.7\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.978797\tvalid_1's auc: 0.89829\n",
      "[2000]\ttraining's auc: 0.983387\tvalid_1's auc: 0.90017\n",
      "[3000]\ttraining's auc: 0.987077\tvalid_1's auc: 0.898556\n",
      "[4000]\ttraining's auc: 0.990148\tvalid_1's auc: 0.897369\n",
      "Early stopping, best iteration is:\n",
      "[1604]\ttraining's auc: 0.981715\tvalid_1's auc: 0.900527\n",
      "===== Training time: 0.70min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9817|val 0.9005\n",
      "===========\n",
      "bagging_fraction: 0.75\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.978916\tvalid_1's auc: 0.898922\n",
      "[2000]\ttraining's auc: 0.983401\tvalid_1's auc: 0.901017\n",
      "[3000]\ttraining's auc: 0.987108\tvalid_1's auc: 0.900188\n",
      "[4000]\ttraining's auc: 0.990211\tvalid_1's auc: 0.898689\n",
      "Early stopping, best iteration is:\n",
      "[1581]\ttraining's auc: 0.981631\tvalid_1's auc: 0.901237\n",
      "===== Training time: 0.70min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9816|val 0.9012\n",
      "===========\n",
      "bagging_fraction: 0.8\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.9789\tvalid_1's auc: 0.898634\n",
      "[2000]\ttraining's auc: 0.983398\tvalid_1's auc: 0.90068\n",
      "[3000]\ttraining's auc: 0.987154\tvalid_1's auc: 0.899381\n",
      "[4000]\ttraining's auc: 0.990241\tvalid_1's auc: 0.898324\n",
      "Early stopping, best iteration is:\n",
      "[1686]\ttraining's auc: 0.982068\tvalid_1's auc: 0.900935\n",
      "===== Training time: 0.69min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9821|val 0.9009\n",
      "===========\n"
     ]
    }
   ],
   "source": [
    "# LGBM round 6: bagging_fraction part 2\n",
    "param_base = {\n",
    "    'boosting_type': 'gbdt', \n",
    "    'boost_from_average': False, \n",
    "    'objective': 'binary', \n",
    "    'tree_learner': 'serial', \n",
    "    'verbosity': 1,\n",
    "    'learning_rate': 0.1, # smaller later \n",
    "    'num_threads': 22,\n",
    "    'metric':'auc',\n",
    "    \n",
    "    'num_leaves': 5, \n",
    "    'max_depth': 15,\n",
    "    'min_data_in_leaf': 150,\n",
    "    'min_sum_hessian_in_leaf': 10,\n",
    "    \n",
    "    'bagging_freq': 1,\n",
    "    'bagging_fraction': 0.4,\n",
    "    'feature_fraction': 0.05\n",
    "    }\n",
    "param_list = [0.65, 0.7, 0.75, 0.8]\n",
    "for curr_param in param_list:\n",
    "    print(\"bagging_fraction: {}\".format(curr_param))\n",
    "    param_base['bagging_fraction'] = curr_param\n",
    "    train_lgbm(param_base, train_data, train_label, val_data, val_label)\n",
    "    print(\"===========\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_fraction: 0.01\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.964989\tvalid_1's auc: 0.897969\n",
      "[2000]\ttraining's auc: 0.975375\tvalid_1's auc: 0.90155\n",
      "[3000]\ttraining's auc: 0.979725\tvalid_1's auc: 0.901026\n",
      "[4000]\ttraining's auc: 0.983015\tvalid_1's auc: 0.899786\n",
      "Early stopping, best iteration is:\n",
      "[1960]\ttraining's auc: 0.97523\tvalid_1's auc: 0.901603\n",
      "===== Training time: 0.70min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9752|val 0.9016\n",
      "===========\n",
      "feature_fraction: 0.03\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.977905\tvalid_1's auc: 0.898022\n",
      "[2000]\ttraining's auc: 0.982139\tvalid_1's auc: 0.900115\n",
      "[3000]\ttraining's auc: 0.985523\tvalid_1's auc: 0.898812\n",
      "[4000]\ttraining's auc: 0.988425\tvalid_1's auc: 0.89719\n",
      "Early stopping, best iteration is:\n",
      "[1788]\ttraining's auc: 0.981355\tvalid_1's auc: 0.900459\n",
      "===== Training time: 0.68min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9814|val 0.9005\n",
      "===========\n",
      "feature_fraction: 0.05\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.978803\tvalid_1's auc: 0.8992\n",
      "[2000]\ttraining's auc: 0.983269\tvalid_1's auc: 0.90135\n",
      "[3000]\ttraining's auc: 0.986954\tvalid_1's auc: 0.899709\n",
      "[4000]\ttraining's auc: 0.989994\tvalid_1's auc: 0.897423\n",
      "Early stopping, best iteration is:\n",
      "[1748]\ttraining's auc: 0.982256\tvalid_1's auc: 0.901476\n",
      "===== Training time: 0.70min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9823|val 0.9015\n",
      "===========\n",
      "feature_fraction: 0.07\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.979188\tvalid_1's auc: 0.899102\n",
      "[2000]\ttraining's auc: 0.983896\tvalid_1's auc: 0.899761\n",
      "[3000]\ttraining's auc: 0.987721\tvalid_1's auc: 0.897941\n",
      "[4000]\ttraining's auc: 0.990779\tvalid_1's auc: 0.89632\n",
      "Early stopping, best iteration is:\n",
      "[1274]\ttraining's auc: 0.980618\tvalid_1's auc: 0.900495\n",
      "===== Training time: 0.64min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9806|val 0.9005\n",
      "===========\n",
      "feature_fraction: 0.09\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.979326\tvalid_1's auc: 0.898582\n",
      "[2000]\ttraining's auc: 0.984265\tvalid_1's auc: 0.899062\n",
      "[3000]\ttraining's auc: 0.988119\tvalid_1's auc: 0.898032\n",
      "[4000]\ttraining's auc: 0.991306\tvalid_1's auc: 0.896561\n",
      "Early stopping, best iteration is:\n",
      "[1255]\ttraining's auc: 0.980779\tvalid_1's auc: 0.900119\n",
      "===== Training time: 0.65min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9808|val 0.9001\n",
      "===========\n",
      "feature_fraction: 0.1\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.97945\tvalid_1's auc: 0.899224\n",
      "[2000]\ttraining's auc: 0.984406\tvalid_1's auc: 0.900546\n",
      "[3000]\ttraining's auc: 0.988314\tvalid_1's auc: 0.899068\n",
      "[4000]\ttraining's auc: 0.991436\tvalid_1's auc: 0.897529\n",
      "Early stopping, best iteration is:\n",
      "[1484]\ttraining's auc: 0.982056\tvalid_1's auc: 0.90093\n",
      "===== Training time: 0.70min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9821|val 0.9009\n",
      "===========\n",
      "feature_fraction: 0.15\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.979844\tvalid_1's auc: 0.898971\n",
      "[2000]\ttraining's auc: 0.985032\tvalid_1's auc: 0.899624\n",
      "[3000]\ttraining's auc: 0.98907\tvalid_1's auc: 0.897651\n",
      "[4000]\ttraining's auc: 0.992205\tvalid_1's auc: 0.895702\n",
      "Early stopping, best iteration is:\n",
      "[1505]\ttraining's auc: 0.982686\tvalid_1's auc: 0.900212\n",
      "===== Training time: 0.74min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9827|val 0.9002\n",
      "===========\n",
      "feature_fraction: 0.2\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.980171\tvalid_1's auc: 0.899153\n",
      "[2000]\ttraining's auc: 0.985375\tvalid_1's auc: 0.899155\n",
      "[3000]\ttraining's auc: 0.989392\tvalid_1's auc: 0.897386\n",
      "[4000]\ttraining's auc: 0.992552\tvalid_1's auc: 0.895718\n",
      "Early stopping, best iteration is:\n",
      "[1332]\ttraining's auc: 0.982095\tvalid_1's auc: 0.900129\n",
      "===== Training time: 0.74min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9821|val 0.9001\n",
      "===========\n",
      "feature_fraction: 0.25\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.980288\tvalid_1's auc: 0.899025\n",
      "[2000]\ttraining's auc: 0.98566\tvalid_1's auc: 0.899087\n",
      "[3000]\ttraining's auc: 0.989757\tvalid_1's auc: 0.897609\n",
      "[4000]\ttraining's auc: 0.992887\tvalid_1's auc: 0.895964\n",
      "Early stopping, best iteration is:\n",
      "[1483]\ttraining's auc: 0.983129\tvalid_1's auc: 0.900132\n",
      "===== Training time: 0.82min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9831|val 0.9001\n",
      "===========\n",
      "feature_fraction: 0.3\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.980509\tvalid_1's auc: 0.899149\n",
      "[2000]\ttraining's auc: 0.985932\tvalid_1's auc: 0.899038\n",
      "[3000]\ttraining's auc: 0.990078\tvalid_1's auc: 0.897101\n",
      "[4000]\ttraining's auc: 0.993193\tvalid_1's auc: 0.895277\n",
      "Early stopping, best iteration is:\n",
      "[1167]\ttraining's auc: 0.981535\tvalid_1's auc: 0.900036\n",
      "===== Training time: 0.81min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9815|val 0.9000\n",
      "===========\n",
      "feature_fraction: 0.35\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.98057\tvalid_1's auc: 0.898887\n",
      "[2000]\ttraining's auc: 0.985973\tvalid_1's auc: 0.898652\n",
      "[3000]\ttraining's auc: 0.990106\tvalid_1's auc: 0.897006\n",
      "[4000]\ttraining's auc: 0.993257\tvalid_1's auc: 0.895767\n",
      "Early stopping, best iteration is:\n",
      "[1287]\ttraining's auc: 0.982294\tvalid_1's auc: 0.899635\n",
      "===== Training time: 0.85min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9823|val 0.8996\n",
      "===========\n",
      "feature_fraction: 0.4\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.980679\tvalid_1's auc: 0.899417\n",
      "[2000]\ttraining's auc: 0.986194\tvalid_1's auc: 0.89897\n",
      "[3000]\ttraining's auc: 0.99032\tvalid_1's auc: 0.897094\n",
      "[4000]\ttraining's auc: 0.993384\tvalid_1's auc: 0.894595\n",
      "Early stopping, best iteration is:\n",
      "[1286]\ttraining's auc: 0.982466\tvalid_1's auc: 0.899917\n",
      "===== Training time: 0.89min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9825|val 0.8999\n",
      "===========\n"
     ]
    }
   ],
   "source": [
    "# LGBM round 6: feature_fraction, still 0.05\n",
    "param_base = {\n",
    "    'boosting_type': 'gbdt', \n",
    "    'boost_from_average': False, \n",
    "    'objective': 'binary', \n",
    "    'tree_learner': 'serial', \n",
    "    'verbosity': 1,\n",
    "    'learning_rate': 0.1, # smaller later \n",
    "    'num_threads': 22,\n",
    "    'metric':'auc',\n",
    "    \n",
    "    'num_leaves': 5, \n",
    "    'max_depth': 15,\n",
    "    'min_data_in_leaf': 150,\n",
    "    'min_sum_hessian_in_leaf': 10,\n",
    "    \n",
    "    'bagging_freq': 1,\n",
    "    'bagging_fraction': 0.6,\n",
    "    'feature_fraction': 0.05\n",
    "    }\n",
    "param_list = [0.01,0.03,0.05,0.07,0.09,0.1,0.15,0.2,0.25,0.3,0.35,0.4]\n",
    "for curr_param in param_list:\n",
    "    print(\"feature_fraction: {}\".format(curr_param))\n",
    "    param_base['feature_fraction'] = curr_param\n",
    "    train_lgbm(param_base, train_data, train_label, val_data, val_label)\n",
    "    print(\"===========\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate: 0.1\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.978803\tvalid_1's auc: 0.8992\n",
      "[2000]\ttraining's auc: 0.983269\tvalid_1's auc: 0.90135\n",
      "[3000]\ttraining's auc: 0.986954\tvalid_1's auc: 0.899709\n",
      "[4000]\ttraining's auc: 0.989994\tvalid_1's auc: 0.897423\n",
      "Early stopping, best iteration is:\n",
      "[1748]\ttraining's auc: 0.982256\tvalid_1's auc: 0.901476\n",
      "===== Training time: 0.74min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9823|val 0.9015\n",
      "===========\n",
      "learning_rate: 0.05\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.974564\tvalid_1's auc: 0.888411\n",
      "[2000]\ttraining's auc: 0.978983\tvalid_1's auc: 0.899222\n",
      "[3000]\ttraining's auc: 0.981355\tvalid_1's auc: 0.901133\n",
      "[4000]\ttraining's auc: 0.983504\tvalid_1's auc: 0.901363\n",
      "[5000]\ttraining's auc: 0.985468\tvalid_1's auc: 0.90106\n",
      "[6000]\ttraining's auc: 0.987254\tvalid_1's auc: 0.900658\n",
      "Early stopping, best iteration is:\n",
      "[3991]\ttraining's auc: 0.983484\tvalid_1's auc: 0.901404\n",
      "===== Training time: 1.06min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9835|val 0.9014\n",
      "===========\n",
      "learning_rate: 0.01\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.953697\tvalid_1's auc: 0.835956\n",
      "[2000]\ttraining's auc: 0.966186\tvalid_1's auc: 0.86362\n",
      "[3000]\ttraining's auc: 0.970569\tvalid_1's auc: 0.877017\n",
      "[4000]\ttraining's auc: 0.973157\tvalid_1's auc: 0.884793\n",
      "[5000]\ttraining's auc: 0.974875\tvalid_1's auc: 0.890089\n",
      "[6000]\ttraining's auc: 0.976221\tvalid_1's auc: 0.893831\n",
      "[7000]\ttraining's auc: 0.977218\tvalid_1's auc: 0.896502\n",
      "[8000]\ttraining's auc: 0.978028\tvalid_1's auc: 0.898348\n",
      "[9000]\ttraining's auc: 0.97871\tvalid_1's auc: 0.899692\n",
      "[10000]\ttraining's auc: 0.979289\tvalid_1's auc: 0.900762\n",
      "[11000]\ttraining's auc: 0.979804\tvalid_1's auc: 0.901392\n",
      "[12000]\ttraining's auc: 0.980293\tvalid_1's auc: 0.90177\n",
      "[13000]\ttraining's auc: 0.980766\tvalid_1's auc: 0.902057\n",
      "[14000]\ttraining's auc: 0.98123\tvalid_1's auc: 0.902212\n",
      "[15000]\ttraining's auc: 0.98168\tvalid_1's auc: 0.902383\n",
      "[16000]\ttraining's auc: 0.982132\tvalid_1's auc: 0.902484\n",
      "[17000]\ttraining's auc: 0.982571\tvalid_1's auc: 0.902613\n",
      "[18000]\ttraining's auc: 0.983012\tvalid_1's auc: 0.902616\n",
      "[19000]\ttraining's auc: 0.983441\tvalid_1's auc: 0.902576\n",
      "[20000]\ttraining's auc: 0.983869\tvalid_1's auc: 0.902583\n",
      "Early stopping, best iteration is:\n",
      "[17883]\ttraining's auc: 0.98296\tvalid_1's auc: 0.902623\n",
      "===== Training time: 2.91min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9830|val 0.9026\n",
      "===========\n",
      "learning_rate: 0.005\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.936116\tvalid_1's auc: 0.812901\n",
      "[2000]\ttraining's auc: 0.953401\tvalid_1's auc: 0.835768\n",
      "[3000]\ttraining's auc: 0.961631\tvalid_1's auc: 0.852724\n",
      "[4000]\ttraining's auc: 0.965826\tvalid_1's auc: 0.863747\n",
      "[5000]\ttraining's auc: 0.968618\tvalid_1's auc: 0.871371\n",
      "[6000]\ttraining's auc: 0.970616\tvalid_1's auc: 0.877177\n",
      "[7000]\ttraining's auc: 0.972073\tvalid_1's auc: 0.881585\n",
      "[8000]\ttraining's auc: 0.973235\tvalid_1's auc: 0.885141\n",
      "[9000]\ttraining's auc: 0.974164\tvalid_1's auc: 0.887927\n",
      "[10000]\ttraining's auc: 0.974955\tvalid_1's auc: 0.890291\n",
      "[11000]\ttraining's auc: 0.975644\tvalid_1's auc: 0.89232\n",
      "[12000]\ttraining's auc: 0.976235\tvalid_1's auc: 0.893968\n",
      "[13000]\ttraining's auc: 0.976767\tvalid_1's auc: 0.895344\n",
      "[14000]\ttraining's auc: 0.977227\tvalid_1's auc: 0.896516\n",
      "[15000]\ttraining's auc: 0.977648\tvalid_1's auc: 0.897487\n",
      "[16000]\ttraining's auc: 0.978033\tvalid_1's auc: 0.898342\n",
      "[17000]\ttraining's auc: 0.978388\tvalid_1's auc: 0.899093\n",
      "[18000]\ttraining's auc: 0.978708\tvalid_1's auc: 0.899678\n",
      "[19000]\ttraining's auc: 0.979008\tvalid_1's auc: 0.900181\n",
      "[20000]\ttraining's auc: 0.979286\tvalid_1's auc: 0.900659\n",
      "[21000]\ttraining's auc: 0.97955\tvalid_1's auc: 0.900969\n",
      "[22000]\ttraining's auc: 0.979812\tvalid_1's auc: 0.901269\n",
      "[23000]\ttraining's auc: 0.980057\tvalid_1's auc: 0.901486\n",
      "[24000]\ttraining's auc: 0.980293\tvalid_1's auc: 0.901705\n",
      "[25000]\ttraining's auc: 0.980531\tvalid_1's auc: 0.901867\n",
      "[26000]\ttraining's auc: 0.980772\tvalid_1's auc: 0.901982\n",
      "[27000]\ttraining's auc: 0.980999\tvalid_1's auc: 0.902121\n",
      "[28000]\ttraining's auc: 0.981224\tvalid_1's auc: 0.902257\n",
      "[29000]\ttraining's auc: 0.981453\tvalid_1's auc: 0.902322\n",
      "[30000]\ttraining's auc: 0.981678\tvalid_1's auc: 0.90238\n",
      "[31000]\ttraining's auc: 0.981901\tvalid_1's auc: 0.902421\n",
      "[32000]\ttraining's auc: 0.982127\tvalid_1's auc: 0.902452\n",
      "[33000]\ttraining's auc: 0.98235\tvalid_1's auc: 0.902461\n",
      "[34000]\ttraining's auc: 0.982573\tvalid_1's auc: 0.902486\n",
      "[35000]\ttraining's auc: 0.982791\tvalid_1's auc: 0.902543\n",
      "[36000]\ttraining's auc: 0.983003\tvalid_1's auc: 0.902572\n",
      "[37000]\ttraining's auc: 0.983225\tvalid_1's auc: 0.902542\n",
      "[38000]\ttraining's auc: 0.983437\tvalid_1's auc: 0.902515\n",
      "Early stopping, best iteration is:\n",
      "[35884]\ttraining's auc: 0.982979\tvalid_1's auc: 0.902576\n",
      "===== Training time: 5.30min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9830|val 0.9026\n",
      "===========\n",
      "learning_rate: 0.002\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.920195\tvalid_1's auc: 0.799209\n",
      "[2000]\ttraining's auc: 0.930357\tvalid_1's auc: 0.808764\n",
      "[3000]\ttraining's auc: 0.938968\tvalid_1's auc: 0.817536\n",
      "[4000]\ttraining's auc: 0.945483\tvalid_1's auc: 0.827371\n",
      "[5000]\ttraining's auc: 0.951781\tvalid_1's auc: 0.83604\n",
      "[6000]\ttraining's auc: 0.95647\tvalid_1's auc: 0.84378\n",
      "[7000]\ttraining's auc: 0.959538\tvalid_1's auc: 0.850039\n",
      "[8000]\ttraining's auc: 0.962121\tvalid_1's auc: 0.855324\n",
      "[9000]\ttraining's auc: 0.964084\tvalid_1's auc: 0.859878\n",
      "[10000]\ttraining's auc: 0.965743\tvalid_1's auc: 0.863933\n",
      "[11000]\ttraining's auc: 0.967036\tvalid_1's auc: 0.867288\n",
      "[12000]\ttraining's auc: 0.968127\tvalid_1's auc: 0.870374\n",
      "[13000]\ttraining's auc: 0.969053\tvalid_1's auc: 0.873055\n",
      "[14000]\ttraining's auc: 0.969865\tvalid_1's auc: 0.875369\n",
      "[15000]\ttraining's auc: 0.970591\tvalid_1's auc: 0.877537\n",
      "[16000]\ttraining's auc: 0.97123\tvalid_1's auc: 0.879428\n",
      "[17000]\ttraining's auc: 0.971793\tvalid_1's auc: 0.881068\n",
      "[18000]\ttraining's auc: 0.97231\tvalid_1's auc: 0.882657\n",
      "[19000]\ttraining's auc: 0.972783\tvalid_1's auc: 0.884018\n",
      "[20000]\ttraining's auc: 0.973215\tvalid_1's auc: 0.885323\n",
      "[21000]\ttraining's auc: 0.973621\tvalid_1's auc: 0.886513\n",
      "[22000]\ttraining's auc: 0.973978\tvalid_1's auc: 0.887594\n",
      "[23000]\ttraining's auc: 0.974321\tvalid_1's auc: 0.888602\n",
      "[24000]\ttraining's auc: 0.974647\tvalid_1's auc: 0.889579\n",
      "[25000]\ttraining's auc: 0.974958\tvalid_1's auc: 0.890448\n",
      "[26000]\ttraining's auc: 0.975248\tvalid_1's auc: 0.891303\n",
      "[27000]\ttraining's auc: 0.975513\tvalid_1's auc: 0.892047\n",
      "[28000]\ttraining's auc: 0.975766\tvalid_1's auc: 0.892742\n",
      "[29000]\ttraining's auc: 0.976007\tvalid_1's auc: 0.89342\n",
      "[30000]\ttraining's auc: 0.976245\tvalid_1's auc: 0.894055\n",
      "[31000]\ttraining's auc: 0.976456\tvalid_1's auc: 0.894629\n",
      "[32000]\ttraining's auc: 0.976664\tvalid_1's auc: 0.895158\n",
      "[33000]\ttraining's auc: 0.976865\tvalid_1's auc: 0.89568\n",
      "[34000]\ttraining's auc: 0.977057\tvalid_1's auc: 0.896183\n",
      "[35000]\ttraining's auc: 0.977233\tvalid_1's auc: 0.896617\n",
      "[36000]\ttraining's auc: 0.977408\tvalid_1's auc: 0.897053\n",
      "[37000]\ttraining's auc: 0.977575\tvalid_1's auc: 0.897471\n",
      "[38000]\ttraining's auc: 0.977735\tvalid_1's auc: 0.897846\n",
      "[39000]\ttraining's auc: 0.977889\tvalid_1's auc: 0.898177\n",
      "[40000]\ttraining's auc: 0.978035\tvalid_1's auc: 0.898479\n",
      "[41000]\ttraining's auc: 0.978179\tvalid_1's auc: 0.898764\n",
      "[42000]\ttraining's auc: 0.978314\tvalid_1's auc: 0.899036\n",
      "[43000]\ttraining's auc: 0.978445\tvalid_1's auc: 0.899299\n",
      "[44000]\ttraining's auc: 0.978574\tvalid_1's auc: 0.899551\n",
      "[45000]\ttraining's auc: 0.978703\tvalid_1's auc: 0.899777\n",
      "[46000]\ttraining's auc: 0.978824\tvalid_1's auc: 0.900004\n",
      "[47000]\ttraining's auc: 0.978944\tvalid_1's auc: 0.900218\n",
      "[48000]\ttraining's auc: 0.979055\tvalid_1's auc: 0.900398\n",
      "[49000]\ttraining's auc: 0.979169\tvalid_1's auc: 0.900556\n",
      "[50000]\ttraining's auc: 0.979278\tvalid_1's auc: 0.900728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[51000]\ttraining's auc: 0.979383\tvalid_1's auc: 0.900877\n",
      "[52000]\ttraining's auc: 0.979489\tvalid_1's auc: 0.901013\n",
      "[53000]\ttraining's auc: 0.979596\tvalid_1's auc: 0.901146\n",
      "[54000]\ttraining's auc: 0.979697\tvalid_1's auc: 0.901261\n",
      "[55000]\ttraining's auc: 0.979798\tvalid_1's auc: 0.901359\n",
      "[56000]\ttraining's auc: 0.979898\tvalid_1's auc: 0.901469\n",
      "[57000]\ttraining's auc: 0.979998\tvalid_1's auc: 0.901549\n",
      "[58000]\ttraining's auc: 0.980095\tvalid_1's auc: 0.901653\n",
      "[59000]\ttraining's auc: 0.980189\tvalid_1's auc: 0.90173\n",
      "[60000]\ttraining's auc: 0.980283\tvalid_1's auc: 0.901813\n",
      "[61000]\ttraining's auc: 0.98038\tvalid_1's auc: 0.901882\n",
      "[62000]\ttraining's auc: 0.980476\tvalid_1's auc: 0.901946\n",
      "[63000]\ttraining's auc: 0.980569\tvalid_1's auc: 0.90201\n",
      "[64000]\ttraining's auc: 0.980665\tvalid_1's auc: 0.902064\n",
      "[65000]\ttraining's auc: 0.980759\tvalid_1's auc: 0.902115\n",
      "[66000]\ttraining's auc: 0.980848\tvalid_1's auc: 0.902159\n",
      "[67000]\ttraining's auc: 0.980941\tvalid_1's auc: 0.902197\n",
      "[68000]\ttraining's auc: 0.981028\tvalid_1's auc: 0.902238\n",
      "[69000]\ttraining's auc: 0.981121\tvalid_1's auc: 0.902271\n",
      "[70000]\ttraining's auc: 0.98121\tvalid_1's auc: 0.902312\n",
      "[71000]\ttraining's auc: 0.9813\tvalid_1's auc: 0.902344\n",
      "[72000]\ttraining's auc: 0.981392\tvalid_1's auc: 0.902377\n",
      "[73000]\ttraining's auc: 0.981484\tvalid_1's auc: 0.9024\n",
      "[74000]\ttraining's auc: 0.981572\tvalid_1's auc: 0.902446\n",
      "[75000]\ttraining's auc: 0.981664\tvalid_1's auc: 0.902475\n",
      "[76000]\ttraining's auc: 0.981753\tvalid_1's auc: 0.902502\n",
      "[77000]\ttraining's auc: 0.981843\tvalid_1's auc: 0.902513\n",
      "[78000]\ttraining's auc: 0.981931\tvalid_1's auc: 0.902519\n",
      "[79000]\ttraining's auc: 0.982021\tvalid_1's auc: 0.90253\n",
      "[80000]\ttraining's auc: 0.98211\tvalid_1's auc: 0.902544\n",
      "[81000]\ttraining's auc: 0.982199\tvalid_1's auc: 0.902565\n",
      "[82000]\ttraining's auc: 0.982287\tvalid_1's auc: 0.902563\n",
      "[83000]\ttraining's auc: 0.982377\tvalid_1's auc: 0.902577\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-22e81bea55e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"learning_rate: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_param\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mparam_base\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'learning_rate'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurr_param\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mtrain_lgbm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_base\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"===========\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-0314a31fa762>\u001b[0m in \u001b[0;36mtrain_lgbm\u001b[0;34m(param, train_data, train_label, val_data, val_label)\u001b[0m\n\u001b[1;32m     11\u001b[0m                     \u001b[0mvalid_sets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlgbm_train_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlgbm_val_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                     \u001b[0mverbose_eval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                     early_stopping_rounds = 3000)\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mtraining_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m60.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"===== Training time: {:.2f}min\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_valid_contain_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                 \u001b[0mevaluation_result_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m             \u001b[0mevaluation_result_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcallbacks_after_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36meval_valid\u001b[0;34m(self, feval)\u001b[0m\n\u001b[1;32m   1975\u001b[0m             \u001b[0mList\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mevaluation\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1976\u001b[0m         \"\"\"\n\u001b[0;32m-> 1977\u001b[0;31m         return [item for i in range_(1, self.__num_dataset)\n\u001b[0m\u001b[1;32m   1978\u001b[0m                 for item in self.__inner_eval(self.name_valid_sets[i - 1], i, feval)]\n\u001b[1;32m   1979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1976\u001b[0m         \"\"\"\n\u001b[1;32m   1977\u001b[0m         return [item for i in range_(1, self.__num_dataset)\n\u001b[0;32m-> 1978\u001b[0;31m                 for item in self.__inner_eval(self.name_valid_sets[i - 1], i, feval)]\n\u001b[0m\u001b[1;32m   1979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1980\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m__inner_eval\u001b[0;34m(self, data_name, data_idx, feval)\u001b[0m\n\u001b[1;32m   2362\u001b[0m                 \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2363\u001b[0m                 \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_out_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2364\u001b[0;31m                 result.ctypes.data_as(ctypes.POINTER(ctypes.c_double))))\n\u001b[0m\u001b[1;32m   2365\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtmp_out_len\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_inner_eval\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2366\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Wrong length of eval results\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# LGBM round 7: final version, learning rate = 0.01\n",
    "param_base = {\n",
    "    'boosting_type': 'gbdt', \n",
    "    'boost_from_average': False, \n",
    "    'objective': 'binary', \n",
    "    'tree_learner': 'serial', \n",
    "    'verbosity': 1,\n",
    "    'learning_rate': 0.1, \n",
    "    'num_threads': 22,\n",
    "    'metric':'auc',\n",
    "    \n",
    "    'num_leaves': 5, \n",
    "    'max_depth': 15,\n",
    "    'min_data_in_leaf': 150,\n",
    "    'min_sum_hessian_in_leaf': 10,\n",
    "    \n",
    "    'bagging_freq': 1,\n",
    "    'bagging_fraction': 0.6,\n",
    "    'feature_fraction': 0.05\n",
    "    }\n",
    "param_list = [0.1, 0.05, 0.01, 0.005, 0.002, 0.001]\n",
    "for curr_param in param_list:\n",
    "    print(\"learning_rate: {}\".format(curr_param))\n",
    "    param_base['learning_rate'] = curr_param\n",
    "    train_lgbm(param_base, train_data, train_label, val_data, val_label)\n",
    "    print(\"===========\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thus this could be final version of LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.953697\tvalid_1's auc: 0.835956\n",
      "[2000]\ttraining's auc: 0.966186\tvalid_1's auc: 0.86362\n",
      "[3000]\ttraining's auc: 0.970569\tvalid_1's auc: 0.877017\n",
      "[4000]\ttraining's auc: 0.973157\tvalid_1's auc: 0.884793\n",
      "[5000]\ttraining's auc: 0.974875\tvalid_1's auc: 0.890089\n",
      "[6000]\ttraining's auc: 0.976221\tvalid_1's auc: 0.893831\n",
      "[7000]\ttraining's auc: 0.977218\tvalid_1's auc: 0.896502\n",
      "[8000]\ttraining's auc: 0.978028\tvalid_1's auc: 0.898348\n",
      "[9000]\ttraining's auc: 0.97871\tvalid_1's auc: 0.899692\n",
      "[10000]\ttraining's auc: 0.979289\tvalid_1's auc: 0.900762\n",
      "[11000]\ttraining's auc: 0.979804\tvalid_1's auc: 0.901392\n",
      "[12000]\ttraining's auc: 0.980293\tvalid_1's auc: 0.90177\n",
      "[13000]\ttraining's auc: 0.980766\tvalid_1's auc: 0.902057\n",
      "[14000]\ttraining's auc: 0.98123\tvalid_1's auc: 0.902212\n",
      "[15000]\ttraining's auc: 0.98168\tvalid_1's auc: 0.902383\n",
      "[16000]\ttraining's auc: 0.982132\tvalid_1's auc: 0.902484\n",
      "[17000]\ttraining's auc: 0.982571\tvalid_1's auc: 0.902613\n",
      "[18000]\ttraining's auc: 0.983012\tvalid_1's auc: 0.902616\n",
      "[19000]\ttraining's auc: 0.983441\tvalid_1's auc: 0.902576\n",
      "[20000]\ttraining's auc: 0.983869\tvalid_1's auc: 0.902583\n",
      "Early stopping, best iteration is:\n",
      "[17883]\ttraining's auc: 0.98296\tvalid_1's auc: 0.902623\n",
      "===== Training time: 3.10min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9830|val 0.9026\n"
     ]
    }
   ],
   "source": [
    "param_base = {\n",
    "    'boosting_type': 'gbdt', \n",
    "    'boost_from_average': False, \n",
    "    'objective': 'binary', \n",
    "    'tree_learner': 'serial', \n",
    "    'verbosity': 1,\n",
    "    'learning_rate': 0.01, \n",
    "    'num_threads': 22,\n",
    "    'metric':'auc',\n",
    "    \n",
    "    'num_leaves': 5, \n",
    "    'max_depth': 15,\n",
    "    'min_data_in_leaf': 150,\n",
    "    'min_sum_hessian_in_leaf': 10,\n",
    "    \n",
    "    'bagging_freq': 1,\n",
    "    'bagging_fraction': 0.6,\n",
    "    'feature_fraction': 0.05\n",
    "    }\n",
    "train_lgbm(param_base, train_data, train_label, val_data, val_label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
