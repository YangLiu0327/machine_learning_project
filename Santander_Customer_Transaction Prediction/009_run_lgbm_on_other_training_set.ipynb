{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run LGBM on other training set\n",
    "\n",
    "In last sections, I get lgbm's parameters on a training set and achieved good performance on the validation set\n",
    "\n",
    "In this section, I will build other form of training set, and check whether the performance on validation set can be better\n",
    "\n",
    "**Specifically, I will change the proportion of resampling and augmentation, and check whether the performance on validation set can be better**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.combine import SMOTETomek\n",
    "from time import time\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 202)\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "df = pd.read_csv(\"data/train.csv\")\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>9.7905</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>21.6042</td>\n",
       "      <td>3.1417</td>\n",
       "      <td>-6.5213</td>\n",
       "      <td>8.2675</td>\n",
       "      <td>14.7222</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4666</td>\n",
       "      <td>4.7433</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>1.4214</td>\n",
       "      <td>23.0347</td>\n",
       "      <td>-1.2706</td>\n",
       "      <td>-2.9275</td>\n",
       "      <td>10.2922</td>\n",
       "      <td>17.9697</td>\n",
       "      <td>-8.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>0</td>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.4905</td>\n",
       "      <td>9.5214</td>\n",
       "      <td>-0.1508</td>\n",
       "      <td>9.1942</td>\n",
       "      <td>13.2876</td>\n",
       "      <td>-1.5121</td>\n",
       "      <td>3.9267</td>\n",
       "      <td>9.5031</td>\n",
       "      <td>17.9974</td>\n",
       "      <td>-8.8104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_code  target    var_0   var_1    var_2   var_3    var_4   var_5   var_6  \\\n",
       "0  train_0       0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187   \n",
       "1  train_1       0  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208   \n",
       "2  train_2       0   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427   \n",
       "3  train_3       0  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428   \n",
       "4  train_4       0   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405   \n",
       "\n",
       "     var_7  ...  var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
       "0  18.6266  ...   4.4354   3.9642   3.1364   1.6910  18.5227  -2.3978   \n",
       "1  16.5338  ...   7.6421   7.7214   2.5837  10.9516  15.4305   2.0339   \n",
       "2  14.6155  ...   2.9057   9.7905   1.6704   1.6858  21.6042   3.1417   \n",
       "3  14.9250  ...   4.4666   4.7433   0.7178   1.4214  23.0347  -1.2706   \n",
       "4  19.2514  ...  -1.4905   9.5214  -0.1508   9.1942  13.2876  -1.5121   \n",
       "\n",
       "   var_196  var_197  var_198  var_199  \n",
       "0   7.8784   8.5635  12.7803  -1.0914  \n",
       "1   8.1267   8.7889  18.3560   1.9518  \n",
       "2  -6.5213   8.2675  14.7222   0.3965  \n",
       "3  -2.9275  10.2922  17.9697  -8.9996  \n",
       "4   3.9267   9.5031  17.9974  -8.8104  \n",
       "\n",
       "[5 rows x 202 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_data, df_label = df[df.columns[2:]], df[df.columns[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>-4.9200</td>\n",
       "      <td>5.7470</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>3.1468</td>\n",
       "      <td>8.0851</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>-4.9193</td>\n",
       "      <td>5.9525</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>9.7905</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>21.6042</td>\n",
       "      <td>3.1417</td>\n",
       "      <td>-6.5213</td>\n",
       "      <td>8.2675</td>\n",
       "      <td>14.7222</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>-5.8609</td>\n",
       "      <td>8.2450</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4666</td>\n",
       "      <td>4.7433</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>1.4214</td>\n",
       "      <td>23.0347</td>\n",
       "      <td>-1.2706</td>\n",
       "      <td>-2.9275</td>\n",
       "      <td>10.2922</td>\n",
       "      <td>17.9697</td>\n",
       "      <td>-8.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>6.2654</td>\n",
       "      <td>7.6784</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.4905</td>\n",
       "      <td>9.5214</td>\n",
       "      <td>-0.1508</td>\n",
       "      <td>9.1942</td>\n",
       "      <td>13.2876</td>\n",
       "      <td>-1.5121</td>\n",
       "      <td>3.9267</td>\n",
       "      <td>9.5031</td>\n",
       "      <td>17.9974</td>\n",
       "      <td>-8.8104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     var_0   var_1    var_2   var_3    var_4   var_5   var_6    var_7   var_8  \\\n",
       "0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187  18.6266 -4.9200   \n",
       "1  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208  16.5338  3.1468   \n",
       "2   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427  14.6155 -4.9193   \n",
       "3  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428  14.9250 -5.8609   \n",
       "4   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405  19.2514  6.2654   \n",
       "\n",
       "    var_9  ...  var_190  var_191  var_192  var_193  var_194  var_195  var_196  \\\n",
       "0  5.7470  ...   4.4354   3.9642   3.1364   1.6910  18.5227  -2.3978   7.8784   \n",
       "1  8.0851  ...   7.6421   7.7214   2.5837  10.9516  15.4305   2.0339   8.1267   \n",
       "2  5.9525  ...   2.9057   9.7905   1.6704   1.6858  21.6042   3.1417  -6.5213   \n",
       "3  8.2450  ...   4.4666   4.7433   0.7178   1.4214  23.0347  -1.2706  -2.9275   \n",
       "4  7.6784  ...  -1.4905   9.5214  -0.1508   9.1942  13.2876  -1.5121   3.9267   \n",
       "\n",
       "   var_197  var_198  var_199  \n",
       "0   8.5635  12.7803  -1.0914  \n",
       "1   8.7889  18.3560   1.9518  \n",
       "2   8.2675  14.7222   0.3965  \n",
       "3  10.2922  17.9697  -8.9996  \n",
       "4   9.5031  17.9974  -8.8104  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target\n",
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_label = pd.DataFrame(df_label)\n",
    "df_label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_label.to_csv(\"data/label_nosmote.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing\n",
    "\n",
    "+ Add sum / min / max / mean / std / skew / kurtosis / median / moving average\n",
    "    + For moving average, read np.ma.average for more details\n",
    "+ Variance of each column\n",
    "+ Here is also a magic feature, read https://www.kaggle.com/c/santander-customer-transaction-prediction/discussion/87486#latest-506429 for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add some basic columns\n",
    "def basic_preprocessing(df):\n",
    "    columns = df.columns\n",
    "    df['sum'] = df[columns].sum(axis=1)  \n",
    "    df['min'] = df[columns].min(axis=1)\n",
    "    df['max'] = df[columns].max(axis=1)\n",
    "    df['mean'] = df[columns].mean(axis=1)\n",
    "    df['std'] = df[columns].std(axis=1)\n",
    "    df['skew'] = df[columns].skew(axis=1)\n",
    "    df['kurt'] = df[columns].kurtosis(axis=1)\n",
    "    df['med'] = df[columns].median(axis=1)\n",
    "    \n",
    "    # add round features\n",
    "    for column in columns:\n",
    "        df['r1_' + column] = np.round(df[column], 1)\n",
    "        df['r2_' + column] = np.round(df[column], 2)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 608)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>...</th>\n",
       "      <th>r1_var_195</th>\n",
       "      <th>r2_var_195</th>\n",
       "      <th>r1_var_196</th>\n",
       "      <th>r2_var_196</th>\n",
       "      <th>r1_var_197</th>\n",
       "      <th>r2_var_197</th>\n",
       "      <th>r1_var_198</th>\n",
       "      <th>r2_var_198</th>\n",
       "      <th>r1_var_199</th>\n",
       "      <th>r2_var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>-4.9200</td>\n",
       "      <td>5.7470</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.4</td>\n",
       "      <td>-2.40</td>\n",
       "      <td>7.9</td>\n",
       "      <td>7.88</td>\n",
       "      <td>8.6</td>\n",
       "      <td>8.56</td>\n",
       "      <td>12.8</td>\n",
       "      <td>12.78</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>-1.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>3.1468</td>\n",
       "      <td>8.0851</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.03</td>\n",
       "      <td>8.1</td>\n",
       "      <td>8.13</td>\n",
       "      <td>8.8</td>\n",
       "      <td>8.79</td>\n",
       "      <td>18.4</td>\n",
       "      <td>18.36</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>-4.9193</td>\n",
       "      <td>5.9525</td>\n",
       "      <td>...</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.14</td>\n",
       "      <td>-6.5</td>\n",
       "      <td>-6.52</td>\n",
       "      <td>8.3</td>\n",
       "      <td>8.27</td>\n",
       "      <td>14.7</td>\n",
       "      <td>14.72</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>-5.8609</td>\n",
       "      <td>8.2450</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>-1.27</td>\n",
       "      <td>-2.9</td>\n",
       "      <td>-2.93</td>\n",
       "      <td>10.3</td>\n",
       "      <td>10.29</td>\n",
       "      <td>18.0</td>\n",
       "      <td>17.97</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-9.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>6.2654</td>\n",
       "      <td>7.6784</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>-1.51</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.93</td>\n",
       "      <td>9.5</td>\n",
       "      <td>9.50</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.00</td>\n",
       "      <td>-8.8</td>\n",
       "      <td>-8.81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 608 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     var_0   var_1    var_2   var_3    var_4   var_5   var_6    var_7   var_8  \\\n",
       "0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187  18.6266 -4.9200   \n",
       "1  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208  16.5338  3.1468   \n",
       "2   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427  14.6155 -4.9193   \n",
       "3  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428  14.9250 -5.8609   \n",
       "4   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405  19.2514  6.2654   \n",
       "\n",
       "    var_9  ...  r1_var_195  r2_var_195  r1_var_196  r2_var_196  r1_var_197  \\\n",
       "0  5.7470  ...        -2.4       -2.40         7.9        7.88         8.6   \n",
       "1  8.0851  ...         2.0        2.03         8.1        8.13         8.8   \n",
       "2  5.9525  ...         3.1        3.14        -6.5       -6.52         8.3   \n",
       "3  8.2450  ...        -1.3       -1.27        -2.9       -2.93        10.3   \n",
       "4  7.6784  ...        -1.5       -1.51         3.9        3.93         9.5   \n",
       "\n",
       "   r2_var_197  r1_var_198  r2_var_198  r1_var_199  r2_var_199  \n",
       "0        8.56        12.8       12.78        -1.1       -1.09  \n",
       "1        8.79        18.4       18.36         2.0        1.95  \n",
       "2        8.27        14.7       14.72         0.4        0.40  \n",
       "3       10.29        18.0       17.97        -9.0       -9.00  \n",
       "4        9.50        18.0       18.00        -8.8       -8.81  \n",
       "\n",
       "[5 rows x 608 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data_prep = df_data.copy()\n",
    "df_data_prep = basic_preprocessing(df_data_prep)\n",
    "print(df_data_prep.shape)\n",
    "df_data_prep.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Split training and validation set\n",
    "\n",
    "20% validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_train_val(df, train_path=None, val_path=None):\n",
    "    df_train, df_val = df[:160000], df[160000:]\n",
    "    print(df_train.shape, df_val.shape)\n",
    "    # df_train.to_csv(train_path)\n",
    "    # df_val.to_csv(val_path)\n",
    "    return df_train, df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160000, 608) (40000, 608)\n",
      "(160000, 1) (40000, 1)\n"
     ]
    }
   ],
   "source": [
    "# train_path = \"data/train_data.csv\"\n",
    "# val_path = \"data/val_data.csv\"\n",
    "train_data, val_data = split_train_val(df_data_prep)\n",
    "# train_path = \"data/train_label.csv\"\n",
    "# val_path = \"data/val_label.csv\"\n",
    "train_label, val_label = split_train_val(df_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Resample and augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this function is modified from https://www.kaggle.com/jiweiliu/lgb-2-leaves-augment\n",
    "def augment(df, features, t):\n",
    "    x = df.iloc[:,:-1].values\n",
    "    y = df['target'].values\n",
    "    \n",
    "    xs,xn = [],[]\n",
    "    for i in range(t):\n",
    "        mask = y>0\n",
    "        x1 = x[mask].copy()\n",
    "        ids = np.arange(x1.shape[0])\n",
    "        for c in range(x1.shape[1]):\n",
    "            np.random.shuffle(ids)\n",
    "            x1[:,c] = x1[ids][:,c]\n",
    "        xs.append(x1)\n",
    "\n",
    "    for i in range(t//2):\n",
    "        mask = y==0\n",
    "        x1 = x[mask].copy()\n",
    "        ids = np.arange(x1.shape[0])\n",
    "        for c in range(x1.shape[1]):\n",
    "            np.random.shuffle(ids)\n",
    "            x1[:,c] = x1[ids][:,c]\n",
    "        xn.append(x1)\n",
    "\n",
    "    xs = np.vstack(xs)\n",
    "    xn = np.vstack(xn)\n",
    "    ys = np.ones(xs.shape[0])\n",
    "    yn = np.zeros(xn.shape[0])\n",
    "    x = np.vstack([x,xs,xn])\n",
    "    y = np.concatenate([y,ys,yn]).astype(np.uint64)\n",
    "    \n",
    "    features = pd.DataFrame(x, columns=features)\n",
    "    labels = pd.DataFrame(y, columns=['target'])\n",
    "    combined = pd.concat([features, labels], axis=1)\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resample_and_augment(df_data, df_label, t=3, zero_fraction=0.75):\n",
    "    \"\"\"\n",
    "    we will sample only 1/4 data from 0s, then combine them with 1s\n",
    "    remember to combine features with label before feeding into this function\n",
    "    \"\"\"\n",
    "    # combine data and target\n",
    "    features = df_data.columns\n",
    "    df_data = pd.concat([df_data, df_label], axis=1)\n",
    "    df_ones = df_data[df_data['target'] == 1]\n",
    "    df_zeros = df_data[df_data['target'] == 0]\n",
    "    print(\"Original 1s {}, 0s {}\".format(df_ones.shape[0], df_zeros.shape[0]))\n",
    "    # augment 1s\n",
    "    aug_ones = augment(df_ones, features, t)\n",
    "    print(\"Now we have {} 1s\".format(aug_ones.shape[0]))\n",
    "    \n",
    "    df_zeros_part = df_zeros.sample(frac=zero_fraction)\n",
    "    print(\"part of 0s: {}\".format(df_zeros_part.shape[0]))\n",
    "    \n",
    "    # combine and shuffle\n",
    "    df_combine = pd.concat([df_zeros_part, aug_ones]).sample(frac=1)\n",
    "    print(\"Combined: {}\".format(df_combine.shape))\n",
    "    train_data_aug = df_combine.iloc[:,:-1]\n",
    "    train_label_aug = df_combine.loc[:,'target']\n",
    "    return train_data_aug, train_label_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original 1s 16049, 0s 143951\n",
      "Now we have 64196 1s\n",
      "part of 0s: 107963\n",
      "Combined: (172159, 609)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(172159, 608)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_aug, train_label_aug = resample_and_augment(train_data, train_label, t=3, zero_fraction=0.75)\n",
    "train_data_aug.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90426</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36931</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26352</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3559</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59031</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       target\n",
       "90426     0.0\n",
       "36931     0.0\n",
       "26352     0.0\n",
       "3559      0.0\n",
       "59031     1.0"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label_aug = pd.DataFrame(train_label_aug)\n",
    "train_label_aug.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGBM on different kinds of training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_base = {\n",
    "    'boosting_type': 'gbdt', \n",
    "    'boost_from_average': False, \n",
    "    'objective': 'binary', \n",
    "    'tree_learner': 'serial', \n",
    "    'verbosity': 1,\n",
    "    'learning_rate': 0.01, \n",
    "    'num_threads': 22,\n",
    "    'metric':'auc',\n",
    "    \n",
    "    'num_leaves': 5, \n",
    "    'max_depth': 15,\n",
    "    'min_data_in_leaf': 150,\n",
    "    'min_sum_hessian_in_leaf': 10,\n",
    "    \n",
    "    'bagging_freq': 1,\n",
    "    'bagging_fraction': 0.6,\n",
    "    'feature_fraction': 0.05\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_lgbm(param, train_data, train_label, val_data, val_label):\n",
    "    print(\"===== Build dataset for lgbm\")\n",
    "    lgbm_train_data = lgb.Dataset(train_data, label=train_label)\n",
    "    lgbm_val_data = lgb.Dataset(val_data, label=val_label)\n",
    "    \n",
    "    print(\"===== Start training\")\n",
    "    start_time = time()\n",
    "    clf = lgb.train(param, \n",
    "                    lgbm_train_data, \n",
    "                    1000000, \n",
    "                    valid_sets = [lgbm_train_data, lgbm_val_data], \n",
    "                    verbose_eval = 1000, \n",
    "                    early_stopping_rounds = 3000)\n",
    "    training_time = (time() - start_time) / 60.\n",
    "    print(\"===== Training time: {:.2f}min\".format(training_time))\n",
    "    \n",
    "    # compute auroc\n",
    "    print(\"===== Get prediction\")\n",
    "    pred_tr = clf.predict(train_data, num_iteration=clf.best_iteration)\n",
    "    pred_cv = clf.predict(val_data, num_iteration=clf.best_iteration)\n",
    "    # get metrics\n",
    "    print(\"===== Build metrics\")\n",
    "    train_label, val_label = np.ravel(train_label), np.ravel(val_label)\n",
    "    a_tr = roc_auc_score(train_label, pred_tr)\n",
    "    a_cv = roc_auc_score(val_label, pred_cv)\n",
    "    progress = \"auroc|train {:.4f}|val {:.4f}\".format(a_tr, a_cv)\n",
    "    print(\"Final result\")\n",
    "    print(progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# t=3, zero_fraction=0.75 (default)\n",
    "# auroc|train 0.9830|val 0.9026"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original 1s 16049, 0s 143951\n",
      "Now we have 64196 1s\n",
      "part of 0s: 143951\n",
      "Combined: (208147, 609)\n"
     ]
    }
   ],
   "source": [
    "# variant 001: t = 3, zero_fraction = 1\n",
    "train_data_aug, train_label_aug = resample_and_augment(train_data, train_label, t=3, zero_fraction=1)\n",
    "train_label_aug = pd.DataFrame(train_label_aug)\n",
    "train_label_aug = train_label_aug.astype(\"int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.954629\tvalid_1's auc: 0.835267\n",
      "[2000]\ttraining's auc: 0.966091\tvalid_1's auc: 0.863185\n",
      "[3000]\ttraining's auc: 0.970495\tvalid_1's auc: 0.876884\n",
      "[4000]\ttraining's auc: 0.973023\tvalid_1's auc: 0.884786\n",
      "[5000]\ttraining's auc: 0.974708\tvalid_1's auc: 0.890103\n",
      "[6000]\ttraining's auc: 0.975992\tvalid_1's auc: 0.893918\n",
      "[7000]\ttraining's auc: 0.97696\tvalid_1's auc: 0.896595\n",
      "[8000]\ttraining's auc: 0.977747\tvalid_1's auc: 0.898532\n",
      "[9000]\ttraining's auc: 0.978393\tvalid_1's auc: 0.899994\n",
      "[10000]\ttraining's auc: 0.978955\tvalid_1's auc: 0.900874\n",
      "[11000]\ttraining's auc: 0.97946\tvalid_1's auc: 0.90165\n",
      "[12000]\ttraining's auc: 0.979942\tvalid_1's auc: 0.90215\n",
      "[13000]\ttraining's auc: 0.980371\tvalid_1's auc: 0.90253\n",
      "[14000]\ttraining's auc: 0.980812\tvalid_1's auc: 0.902745\n",
      "[15000]\ttraining's auc: 0.981236\tvalid_1's auc: 0.902948\n",
      "[16000]\ttraining's auc: 0.981668\tvalid_1's auc: 0.90308\n",
      "[17000]\ttraining's auc: 0.982083\tvalid_1's auc: 0.90307\n",
      "[18000]\ttraining's auc: 0.982495\tvalid_1's auc: 0.903129\n",
      "[19000]\ttraining's auc: 0.982892\tvalid_1's auc: 0.903126\n",
      "[20000]\ttraining's auc: 0.983292\tvalid_1's auc: 0.903217\n",
      "[21000]\ttraining's auc: 0.983688\tvalid_1's auc: 0.903169\n",
      "[22000]\ttraining's auc: 0.984081\tvalid_1's auc: 0.903122\n",
      "Early stopping, best iteration is:\n",
      "[19671]\ttraining's auc: 0.983164\tvalid_1's auc: 0.90323\n",
      "===== Training time: 3.69min\n",
      "===== Get prediction\n",
      "===== Build metrics\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'roc_auc_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-5c91c2f415a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_lgbm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_base\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data_aug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_label_aug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-0314a31fa762>\u001b[0m in \u001b[0;36mtrain_lgbm\u001b[0;34m(param, train_data, train_label, val_data, val_label)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"===== Build metrics\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mtrain_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0ma_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0ma_cv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_cv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mprogress\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"auroc|train {:.4f}|val {:.4f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_cv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'roc_auc_score' is not defined"
     ]
    }
   ],
   "source": [
    "train_lgbm(param_base, train_data_aug, train_label_aug, val_data, val_label)\n",
    "# training's auc: 0.983164 valid_1's auc: 0.90323"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original 1s 16049, 0s 143951\n",
      "Now we have 64196 1s\n",
      "part of 0s: 71976\n",
      "Combined: (136172, 609)\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.951308\tvalid_1's auc: 0.833722\n",
      "[2000]\ttraining's auc: 0.96557\tvalid_1's auc: 0.8627\n",
      "[3000]\ttraining's auc: 0.970548\tvalid_1's auc: 0.877038\n",
      "[4000]\ttraining's auc: 0.973331\tvalid_1's auc: 0.88518\n",
      "[5000]\ttraining's auc: 0.975186\tvalid_1's auc: 0.890699\n",
      "[6000]\ttraining's auc: 0.97654\tvalid_1's auc: 0.894449\n",
      "[7000]\ttraining's auc: 0.977578\tvalid_1's auc: 0.89705\n",
      "[8000]\ttraining's auc: 0.978431\tvalid_1's auc: 0.898908\n",
      "[9000]\ttraining's auc: 0.979134\tvalid_1's auc: 0.900168\n",
      "[10000]\ttraining's auc: 0.979757\tvalid_1's auc: 0.901066\n",
      "[11000]\ttraining's auc: 0.980326\tvalid_1's auc: 0.901606\n",
      "[12000]\ttraining's auc: 0.980847\tvalid_1's auc: 0.901929\n",
      "[13000]\ttraining's auc: 0.981373\tvalid_1's auc: 0.902246\n",
      "[14000]\ttraining's auc: 0.981878\tvalid_1's auc: 0.902344\n",
      "[15000]\ttraining's auc: 0.98237\tvalid_1's auc: 0.902378\n",
      "[16000]\ttraining's auc: 0.982859\tvalid_1's auc: 0.902489\n",
      "[17000]\ttraining's auc: 0.983343\tvalid_1's auc: 0.902506\n",
      "[18000]\ttraining's auc: 0.983807\tvalid_1's auc: 0.902454\n",
      "[19000]\ttraining's auc: 0.984264\tvalid_1's auc: 0.902428\n",
      "Early stopping, best iteration is:\n",
      "[16383]\ttraining's auc: 0.983047\tvalid_1's auc: 0.90254\n",
      "===== Training time: 2.16min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9830|val 0.9025\n"
     ]
    }
   ],
   "source": [
    "# variant 002: t = 3, zero_fraction = 0.50\n",
    "train_data_aug, train_label_aug = resample_and_augment(train_data, train_label, t=3, zero_fraction=0.50)\n",
    "train_label_aug = pd.DataFrame(train_label_aug)\n",
    "train_label_aug = train_label_aug.astype(\"int64\")\n",
    "train_lgbm(param_base, train_data_aug, train_label_aug, val_data, val_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original 1s 16049, 0s 143951\n",
      "Now we have 64196 1s\n",
      "part of 0s: 35988\n",
      "Combined: (100184, 609)\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.946879\tvalid_1's auc: 0.830813\n",
      "[2000]\ttraining's auc: 0.963882\tvalid_1's auc: 0.86097\n",
      "[3000]\ttraining's auc: 0.970503\tvalid_1's auc: 0.875983\n",
      "[4000]\ttraining's auc: 0.973839\tvalid_1's auc: 0.88449\n",
      "[5000]\ttraining's auc: 0.975921\tvalid_1's auc: 0.890018\n",
      "[6000]\ttraining's auc: 0.977406\tvalid_1's auc: 0.89368\n",
      "[7000]\ttraining's auc: 0.978537\tvalid_1's auc: 0.8961\n",
      "[8000]\ttraining's auc: 0.979453\tvalid_1's auc: 0.897778\n",
      "[9000]\ttraining's auc: 0.980227\tvalid_1's auc: 0.899026\n",
      "[10000]\ttraining's auc: 0.98093\tvalid_1's auc: 0.899872\n",
      "[11000]\ttraining's auc: 0.981571\tvalid_1's auc: 0.900366\n",
      "[12000]\ttraining's auc: 0.982205\tvalid_1's auc: 0.900821\n",
      "[13000]\ttraining's auc: 0.982817\tvalid_1's auc: 0.901103\n",
      "[14000]\ttraining's auc: 0.983414\tvalid_1's auc: 0.901229\n",
      "[15000]\ttraining's auc: 0.984022\tvalid_1's auc: 0.901316\n",
      "[16000]\ttraining's auc: 0.984595\tvalid_1's auc: 0.901232\n",
      "[17000]\ttraining's auc: 0.985157\tvalid_1's auc: 0.901218\n",
      "Early stopping, best iteration is:\n",
      "[14802]\ttraining's auc: 0.983901\tvalid_1's auc: 0.901343\n",
      "===== Training time: 1.59min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9839|val 0.9013\n"
     ]
    }
   ],
   "source": [
    "# variant 003: t = 3, zero_fraction = 0.25\n",
    "train_data_aug, train_label_aug = resample_and_augment(train_data, train_label, t=3, zero_fraction=0.25)\n",
    "train_label_aug = pd.DataFrame(train_label_aug)\n",
    "train_label_aug = train_label_aug.astype(\"int64\")\n",
    "train_lgbm(param_base, train_data_aug, train_label_aug, val_data, val_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.850095\tvalid_1's auc: 0.847071\n",
      "[2000]\ttraining's auc: 0.8802\tvalid_1's auc: 0.872906\n",
      "[3000]\ttraining's auc: 0.894248\tvalid_1's auc: 0.884561\n",
      "[4000]\ttraining's auc: 0.902668\tvalid_1's auc: 0.890981\n",
      "[5000]\ttraining's auc: 0.908267\tvalid_1's auc: 0.895264\n",
      "[6000]\ttraining's auc: 0.912363\tvalid_1's auc: 0.897825\n",
      "[7000]\ttraining's auc: 0.915532\tvalid_1's auc: 0.899648\n",
      "[8000]\ttraining's auc: 0.918101\tvalid_1's auc: 0.900834\n",
      "[9000]\ttraining's auc: 0.920288\tvalid_1's auc: 0.901627\n",
      "[10000]\ttraining's auc: 0.922338\tvalid_1's auc: 0.902165\n",
      "[11000]\ttraining's auc: 0.924199\tvalid_1's auc: 0.902358\n",
      "[12000]\ttraining's auc: 0.925984\tvalid_1's auc: 0.902624\n",
      "[13000]\ttraining's auc: 0.927725\tvalid_1's auc: 0.9027\n",
      "[14000]\ttraining's auc: 0.92947\tvalid_1's auc: 0.902749\n",
      "[15000]\ttraining's auc: 0.931133\tvalid_1's auc: 0.902734\n",
      "[16000]\ttraining's auc: 0.932756\tvalid_1's auc: 0.902803\n",
      "[17000]\ttraining's auc: 0.934371\tvalid_1's auc: 0.90284\n",
      "[18000]\ttraining's auc: 0.935935\tvalid_1's auc: 0.902786\n",
      "[19000]\ttraining's auc: 0.937513\tvalid_1's auc: 0.902716\n",
      "Early stopping, best iteration is:\n",
      "[16343]\ttraining's auc: 0.933307\tvalid_1's auc: 0.902858\n",
      "===== Training time: 2.50min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9333|val 0.9029\n"
     ]
    }
   ],
   "source": [
    "# variant 004: t = 1, zero_fraction = 1, i.e. this is dataset without resampling and augmenting\n",
    "# train_data_aug, train_label_aug = resample_and_augment(train_data, train_label, t=1, zero_fraction=1)\n",
    "train_data_aug = train_data.copy()\n",
    "train_label_aug = train_label.copy().astype(\"int64\")\n",
    "train_lgbm(param_base, train_data_aug, train_label_aug, val_data, val_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original 1s 16049, 0s 143951\n",
      "Now we have 48147 1s\n",
      "part of 0s: 143951\n",
      "Combined: (192098, 609)\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.94184\tvalid_1's auc: 0.838381\n",
      "[2000]\ttraining's auc: 0.955878\tvalid_1's auc: 0.865369\n",
      "[3000]\ttraining's auc: 0.96144\tvalid_1's auc: 0.8784\n",
      "[4000]\ttraining's auc: 0.964635\tvalid_1's auc: 0.886184\n",
      "[5000]\ttraining's auc: 0.966826\tvalid_1's auc: 0.891305\n",
      "[6000]\ttraining's auc: 0.968427\tvalid_1's auc: 0.894746\n",
      "[7000]\ttraining's auc: 0.969693\tvalid_1's auc: 0.897219\n",
      "[8000]\ttraining's auc: 0.970696\tvalid_1's auc: 0.89902\n",
      "[9000]\ttraining's auc: 0.971524\tvalid_1's auc: 0.900204\n",
      "[10000]\ttraining's auc: 0.972264\tvalid_1's auc: 0.901096\n",
      "[11000]\ttraining's auc: 0.972919\tvalid_1's auc: 0.901803\n",
      "[12000]\ttraining's auc: 0.973539\tvalid_1's auc: 0.902261\n",
      "[13000]\ttraining's auc: 0.974121\tvalid_1's auc: 0.902516\n",
      "[14000]\ttraining's auc: 0.974721\tvalid_1's auc: 0.902682\n",
      "[15000]\ttraining's auc: 0.975286\tvalid_1's auc: 0.902821\n",
      "[16000]\ttraining's auc: 0.975858\tvalid_1's auc: 0.902847\n",
      "[17000]\ttraining's auc: 0.976413\tvalid_1's auc: 0.902933\n",
      "[18000]\ttraining's auc: 0.976958\tvalid_1's auc: 0.902945\n",
      "[19000]\ttraining's auc: 0.977499\tvalid_1's auc: 0.902938\n",
      "[20000]\ttraining's auc: 0.978025\tvalid_1's auc: 0.902893\n",
      "[21000]\ttraining's auc: 0.978538\tvalid_1's auc: 0.902862\n",
      "Early stopping, best iteration is:\n",
      "[18624]\ttraining's auc: 0.977293\tvalid_1's auc: 0.902991\n",
      "===== Training time: 3.23min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9773|val 0.9030\n"
     ]
    }
   ],
   "source": [
    "# variant 005: t = 2, zero_fraction = 1\n",
    "train_data_aug, train_label_aug = resample_and_augment(train_data, train_label, t=2, zero_fraction=1)\n",
    "train_label_aug = pd.DataFrame(train_label_aug)\n",
    "train_label_aug = train_label_aug.astype(\"int64\")\n",
    "train_lgbm(param_base, train_data_aug, train_label_aug, val_data, val_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original 1s 16049, 0s 143951\n",
      "Now we have 48147 1s\n",
      "part of 0s: 107963\n",
      "Combined: (156110, 609)\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.941058\tvalid_1's auc: 0.837121\n",
      "[2000]\ttraining's auc: 0.955865\tvalid_1's auc: 0.865111\n",
      "[3000]\ttraining's auc: 0.961501\tvalid_1's auc: 0.878448\n",
      "[4000]\ttraining's auc: 0.964794\tvalid_1's auc: 0.88613\n",
      "[5000]\ttraining's auc: 0.967075\tvalid_1's auc: 0.89119\n",
      "[6000]\ttraining's auc: 0.968732\tvalid_1's auc: 0.89469\n",
      "[7000]\ttraining's auc: 0.970041\tvalid_1's auc: 0.897245\n",
      "[8000]\ttraining's auc: 0.971045\tvalid_1's auc: 0.898989\n",
      "[9000]\ttraining's auc: 0.971914\tvalid_1's auc: 0.900209\n",
      "[10000]\ttraining's auc: 0.97265\tvalid_1's auc: 0.901083\n",
      "[11000]\ttraining's auc: 0.973336\tvalid_1's auc: 0.901664\n",
      "[12000]\ttraining's auc: 0.973989\tvalid_1's auc: 0.902021\n",
      "[13000]\ttraining's auc: 0.974614\tvalid_1's auc: 0.902251\n",
      "[14000]\ttraining's auc: 0.975223\tvalid_1's auc: 0.90233\n",
      "[15000]\ttraining's auc: 0.975827\tvalid_1's auc: 0.902468\n",
      "[16000]\ttraining's auc: 0.976414\tvalid_1's auc: 0.902607\n",
      "[17000]\ttraining's auc: 0.976992\tvalid_1's auc: 0.902568\n",
      "[18000]\ttraining's auc: 0.977576\tvalid_1's auc: 0.902584\n",
      "[19000]\ttraining's auc: 0.978135\tvalid_1's auc: 0.902589\n",
      "[20000]\ttraining's auc: 0.978691\tvalid_1's auc: 0.902555\n",
      "[21000]\ttraining's auc: 0.97923\tvalid_1's auc: 0.902524\n",
      "Early stopping, best iteration is:\n",
      "[18529]\ttraining's auc: 0.977879\tvalid_1's auc: 0.902623\n",
      "===== Training time: 2.68min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9779|val 0.9026\n"
     ]
    }
   ],
   "source": [
    "# variant 006: t = 2, zero_fraction = 0.75\n",
    "train_data_aug, train_label_aug = resample_and_augment(train_data, train_label, t=2, zero_fraction=0.75)\n",
    "train_label_aug = pd.DataFrame(train_label_aug)\n",
    "train_label_aug = train_label_aug.astype(\"int64\")\n",
    "train_lgbm(param_base, train_data_aug, train_label_aug, val_data, val_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original 1s 16049, 0s 143951\n",
      "Now we have 80245 1s\n",
      "part of 0s: 143951\n",
      "Combined: (224196, 609)\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.960825\tvalid_1's auc: 0.834688\n",
      "[2000]\ttraining's auc: 0.972488\tvalid_1's auc: 0.862765\n",
      "[3000]\ttraining's auc: 0.976149\tvalid_1's auc: 0.876318\n",
      "[4000]\ttraining's auc: 0.978205\tvalid_1's auc: 0.884361\n",
      "[5000]\ttraining's auc: 0.979588\tvalid_1's auc: 0.889884\n",
      "[6000]\ttraining's auc: 0.98061\tvalid_1's auc: 0.893642\n",
      "[7000]\ttraining's auc: 0.981415\tvalid_1's auc: 0.896445\n",
      "[8000]\ttraining's auc: 0.982046\tvalid_1's auc: 0.89832\n",
      "[9000]\ttraining's auc: 0.982574\tvalid_1's auc: 0.899888\n",
      "[10000]\ttraining's auc: 0.983027\tvalid_1's auc: 0.900921\n",
      "[11000]\ttraining's auc: 0.98343\tvalid_1's auc: 0.901615\n",
      "[12000]\ttraining's auc: 0.983798\tvalid_1's auc: 0.902113\n",
      "[13000]\ttraining's auc: 0.984164\tvalid_1's auc: 0.902474\n",
      "[14000]\ttraining's auc: 0.984519\tvalid_1's auc: 0.902687\n",
      "[15000]\ttraining's auc: 0.984864\tvalid_1's auc: 0.902787\n",
      "[16000]\ttraining's auc: 0.985197\tvalid_1's auc: 0.902863\n",
      "[17000]\ttraining's auc: 0.985533\tvalid_1's auc: 0.90298\n",
      "[18000]\ttraining's auc: 0.985859\tvalid_1's auc: 0.903047\n",
      "[19000]\ttraining's auc: 0.98618\tvalid_1's auc: 0.90296\n",
      "[20000]\ttraining's auc: 0.986499\tvalid_1's auc: 0.902913\n",
      "Early stopping, best iteration is:\n",
      "[17841]\ttraining's auc: 0.985808\tvalid_1's auc: 0.903064\n",
      "===== Training time: 3.52min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9858|val 0.9031\n"
     ]
    }
   ],
   "source": [
    "# variant 007: t = 4, zero_fraction = 1\n",
    "train_data_aug, train_label_aug = resample_and_augment(train_data, train_label, t=4, zero_fraction=1)\n",
    "train_label_aug = pd.DataFrame(train_label_aug)\n",
    "train_label_aug = train_label_aug.astype(\"int64\")\n",
    "train_lgbm(param_base, train_data_aug, train_label_aug, val_data, val_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original 1s 16049, 0s 143951\n",
      "Now we have 80245 1s\n",
      "part of 0s: 107963\n",
      "Combined: (188208, 609)\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.960205\tvalid_1's auc: 0.833062\n",
      "[2000]\ttraining's auc: 0.972098\tvalid_1's auc: 0.861646\n",
      "[3000]\ttraining's auc: 0.976043\tvalid_1's auc: 0.875457\n",
      "[4000]\ttraining's auc: 0.978251\tvalid_1's auc: 0.883816\n",
      "[5000]\ttraining's auc: 0.979698\tvalid_1's auc: 0.889454\n",
      "[6000]\ttraining's auc: 0.980735\tvalid_1's auc: 0.892974\n",
      "[7000]\ttraining's auc: 0.981557\tvalid_1's auc: 0.895876\n",
      "[8000]\ttraining's auc: 0.982227\tvalid_1's auc: 0.897878\n",
      "[9000]\ttraining's auc: 0.982766\tvalid_1's auc: 0.899305\n",
      "[10000]\ttraining's auc: 0.983247\tvalid_1's auc: 0.900334\n",
      "[11000]\ttraining's auc: 0.983674\tvalid_1's auc: 0.901227\n",
      "[12000]\ttraining's auc: 0.984073\tvalid_1's auc: 0.901781\n",
      "[13000]\ttraining's auc: 0.984448\tvalid_1's auc: 0.902041\n",
      "[14000]\ttraining's auc: 0.984816\tvalid_1's auc: 0.902273\n",
      "[15000]\ttraining's auc: 0.985178\tvalid_1's auc: 0.902408\n",
      "[16000]\ttraining's auc: 0.985534\tvalid_1's auc: 0.902533\n",
      "[17000]\ttraining's auc: 0.985889\tvalid_1's auc: 0.902646\n",
      "[18000]\ttraining's auc: 0.986238\tvalid_1's auc: 0.902687\n",
      "[19000]\ttraining's auc: 0.98658\tvalid_1's auc: 0.902637\n",
      "[20000]\ttraining's auc: 0.986921\tvalid_1's auc: 0.902685\n",
      "[21000]\ttraining's auc: 0.987246\tvalid_1's auc: 0.902725\n",
      "[22000]\ttraining's auc: 0.987564\tvalid_1's auc: 0.9027\n",
      "[23000]\ttraining's auc: 0.987882\tvalid_1's auc: 0.902685\n",
      "Early stopping, best iteration is:\n",
      "[20844]\ttraining's auc: 0.987194\tvalid_1's auc: 0.902759\n",
      "===== Training time: 3.50min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9872|val 0.9028\n"
     ]
    }
   ],
   "source": [
    "# variant 008: t = 4, zero_fraction = 0.75\n",
    "train_data_aug, train_label_aug = resample_and_augment(train_data, train_label, t=4, zero_fraction=0.75)\n",
    "train_label_aug = pd.DataFrame(train_label_aug)\n",
    "train_label_aug = train_label_aug.astype(\"int64\")\n",
    "train_lgbm(param_base, train_data_aug, train_label_aug, val_data, val_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finished, in next part we will try to run on dataset with dimension reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA following is not used --> reduce the performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. PCA\n",
    "Here I reduce the dimension to 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dimension_reduction(df, n_components=200):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    df_processed = pca.fit_transform(df)\n",
    "    df_processed = pd.DataFrame(df_processed, columns = ['var_pca_{}'.format(i) for i in range(n_components)])\n",
    "    return df_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 200)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_pca_0</th>\n",
       "      <th>var_pca_1</th>\n",
       "      <th>var_pca_2</th>\n",
       "      <th>var_pca_3</th>\n",
       "      <th>var_pca_4</th>\n",
       "      <th>var_pca_5</th>\n",
       "      <th>var_pca_6</th>\n",
       "      <th>var_pca_7</th>\n",
       "      <th>var_pca_8</th>\n",
       "      <th>var_pca_9</th>\n",
       "      <th>...</th>\n",
       "      <th>var_pca_190</th>\n",
       "      <th>var_pca_191</th>\n",
       "      <th>var_pca_192</th>\n",
       "      <th>var_pca_193</th>\n",
       "      <th>var_pca_194</th>\n",
       "      <th>var_pca_195</th>\n",
       "      <th>var_pca_196</th>\n",
       "      <th>var_pca_197</th>\n",
       "      <th>var_pca_198</th>\n",
       "      <th>var_pca_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-105.860128</td>\n",
       "      <td>-5.400743</td>\n",
       "      <td>37.417087</td>\n",
       "      <td>3.935585</td>\n",
       "      <td>3.777360</td>\n",
       "      <td>4.637825</td>\n",
       "      <td>-18.165755</td>\n",
       "      <td>14.889708</td>\n",
       "      <td>-29.852264</td>\n",
       "      <td>6.936472</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.087427</td>\n",
       "      <td>0.108608</td>\n",
       "      <td>-0.786297</td>\n",
       "      <td>0.853786</td>\n",
       "      <td>-0.416321</td>\n",
       "      <td>-0.124596</td>\n",
       "      <td>0.560179</td>\n",
       "      <td>0.046222</td>\n",
       "      <td>-0.049892</td>\n",
       "      <td>-0.254745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-54.355348</td>\n",
       "      <td>-70.943602</td>\n",
       "      <td>-28.984502</td>\n",
       "      <td>-30.938672</td>\n",
       "      <td>1.802316</td>\n",
       "      <td>-2.775054</td>\n",
       "      <td>2.662385</td>\n",
       "      <td>-21.835452</td>\n",
       "      <td>-10.575077</td>\n",
       "      <td>21.371416</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069770</td>\n",
       "      <td>-0.958390</td>\n",
       "      <td>0.152369</td>\n",
       "      <td>0.402786</td>\n",
       "      <td>0.310333</td>\n",
       "      <td>-0.335566</td>\n",
       "      <td>-0.435642</td>\n",
       "      <td>0.488061</td>\n",
       "      <td>-0.054247</td>\n",
       "      <td>0.210107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>110.486360</td>\n",
       "      <td>24.541343</td>\n",
       "      <td>3.941811</td>\n",
       "      <td>23.961675</td>\n",
       "      <td>-15.154132</td>\n",
       "      <td>-9.355453</td>\n",
       "      <td>4.965564</td>\n",
       "      <td>35.465815</td>\n",
       "      <td>4.862782</td>\n",
       "      <td>0.919669</td>\n",
       "      <td>...</td>\n",
       "      <td>0.240640</td>\n",
       "      <td>-0.281654</td>\n",
       "      <td>0.025007</td>\n",
       "      <td>0.780489</td>\n",
       "      <td>-0.774717</td>\n",
       "      <td>0.377030</td>\n",
       "      <td>-0.357587</td>\n",
       "      <td>0.188147</td>\n",
       "      <td>0.243865</td>\n",
       "      <td>-0.336344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69.503042</td>\n",
       "      <td>-10.319518</td>\n",
       "      <td>-26.484079</td>\n",
       "      <td>22.524163</td>\n",
       "      <td>-37.881464</td>\n",
       "      <td>-15.064502</td>\n",
       "      <td>27.688344</td>\n",
       "      <td>14.940958</td>\n",
       "      <td>14.542261</td>\n",
       "      <td>-4.162862</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.109669</td>\n",
       "      <td>-0.399767</td>\n",
       "      <td>-0.412265</td>\n",
       "      <td>-0.472733</td>\n",
       "      <td>0.074901</td>\n",
       "      <td>-0.754768</td>\n",
       "      <td>-0.589803</td>\n",
       "      <td>-0.404724</td>\n",
       "      <td>-0.304190</td>\n",
       "      <td>-0.307361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.596137</td>\n",
       "      <td>-93.729275</td>\n",
       "      <td>-43.654269</td>\n",
       "      <td>35.223109</td>\n",
       "      <td>44.294176</td>\n",
       "      <td>-10.231406</td>\n",
       "      <td>19.801837</td>\n",
       "      <td>-28.270031</td>\n",
       "      <td>31.285243</td>\n",
       "      <td>-27.998473</td>\n",
       "      <td>...</td>\n",
       "      <td>0.405957</td>\n",
       "      <td>2.634627</td>\n",
       "      <td>-0.538385</td>\n",
       "      <td>-0.123605</td>\n",
       "      <td>-0.193773</td>\n",
       "      <td>0.195125</td>\n",
       "      <td>-0.091210</td>\n",
       "      <td>-0.423971</td>\n",
       "      <td>-0.280581</td>\n",
       "      <td>0.246918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    var_pca_0  var_pca_1  var_pca_2  var_pca_3  var_pca_4  var_pca_5  \\\n",
       "0 -105.860128  -5.400743  37.417087   3.935585   3.777360   4.637825   \n",
       "1  -54.355348 -70.943602 -28.984502 -30.938672   1.802316  -2.775054   \n",
       "2  110.486360  24.541343   3.941811  23.961675 -15.154132  -9.355453   \n",
       "3   69.503042 -10.319518 -26.484079  22.524163 -37.881464 -15.064502   \n",
       "4   13.596137 -93.729275 -43.654269  35.223109  44.294176 -10.231406   \n",
       "\n",
       "   var_pca_6  var_pca_7  var_pca_8  var_pca_9  ...  var_pca_190  var_pca_191  \\\n",
       "0 -18.165755  14.889708 -29.852264   6.936472  ...    -0.087427     0.108608   \n",
       "1   2.662385 -21.835452 -10.575077  21.371416  ...     0.069770    -0.958390   \n",
       "2   4.965564  35.465815   4.862782   0.919669  ...     0.240640    -0.281654   \n",
       "3  27.688344  14.940958  14.542261  -4.162862  ...    -0.109669    -0.399767   \n",
       "4  19.801837 -28.270031  31.285243 -27.998473  ...     0.405957     2.634627   \n",
       "\n",
       "   var_pca_192  var_pca_193  var_pca_194  var_pca_195  var_pca_196  \\\n",
       "0    -0.786297     0.853786    -0.416321    -0.124596     0.560179   \n",
       "1     0.152369     0.402786     0.310333    -0.335566    -0.435642   \n",
       "2     0.025007     0.780489    -0.774717     0.377030    -0.357587   \n",
       "3    -0.412265    -0.472733     0.074901    -0.754768    -0.589803   \n",
       "4    -0.538385    -0.123605    -0.193773     0.195125    -0.091210   \n",
       "\n",
       "   var_pca_197  var_pca_198  var_pca_199  \n",
       "0     0.046222    -0.049892    -0.254745  \n",
       "1     0.488061    -0.054247     0.210107  \n",
       "2     0.188147     0.243865    -0.336344  \n",
       "3    -0.404724    -0.304190    -0.307361  \n",
       "4    -0.423971    -0.280581     0.246918  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data_pca = dimension_reduction(df_data_prep)\n",
    "print(df_data_pca.shape)\n",
    "df_data_pca.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160000, 200) (40000, 200)\n",
      "(160000, 1) (40000, 1)\n"
     ]
    }
   ],
   "source": [
    "train_data, val_data = split_train_val(df_data_pca)\n",
    "train_label, val_label = split_train_val(df_label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
