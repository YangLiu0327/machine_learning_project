{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CPb9gJQhuT0-"
   },
   "source": [
    "# Run LGBM on other training set\n",
    "\n",
    "In last sections, I get lgbm's parameters on a training set and achieved good performance on the validation set\n",
    "\n",
    "In this section, I will build other form of training set, and check whether the performance on validation set can be better\n",
    "\n",
    "**Specifically, I will reduce the dimension via PCA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6CclHhPpuT0_"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.combine import SMOTETomek\n",
    "from time import time\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6Hg7yCpRuT1B"
   },
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "olD3metnuT1C"
   },
   "outputs": [],
   "source": [
    "def load_data(train_data_path, train_label_path, val_data_path, val_label_path):\n",
    "    val_data = pd.read_csv(val_data_path)\n",
    "    val_data.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "    val_label = pd.read_csv(val_label_path)\n",
    "    val_label.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "    train_data = pd.read_csv(train_data_path)\n",
    "    train_data.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "    train_data.columns = val_data.columns\n",
    "    train_label = pd.read_csv(train_label_path)\n",
    "    train_label.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "    train_label.columns = val_label.columns\n",
    "    \n",
    "    print(\"Train: {},{}\".format(train_data.shape, train_label.shape))\n",
    "    print(\"Val: {}, {}\".format(val_data.shape, val_label.shape))\n",
    "    \n",
    "    return train_data, train_label, val_data, val_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eSPYy2OmuT1E",
    "outputId": "c8348fcf-4167-4a97-c2de-ee61805be7d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (172159, 608),(172159, 1)\n",
      "Val: (40000, 608), (40000, 1)\n"
     ]
    }
   ],
   "source": [
    "train_data_path = \"data/train_data_aug.csv\"\n",
    "train_label_path = \"data/train_label_aug.csv\"\n",
    "val_data_path = \"data/val_data.csv\"\n",
    "val_label_path = \"data/val_label.csv\"\n",
    "train_data, train_label, val_data, val_label = load_data(train_data_path, train_label_path, val_data_path, val_label_path)\n",
    "train_label = train_label.astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lJZJytn-uT1G"
   },
   "source": [
    "## LGBM on different kinds of training set\n",
    "\n",
    "In previous sections, without dimension reduction, the result is \n",
    "\n",
    "auroc|train 0.9830|val 0.9026\n",
    "\n",
    "Now we will use PCA to reduce dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0D9aYqz7uT1H"
   },
   "outputs": [],
   "source": [
    "param_base = {\n",
    "    'boosting_type': 'gbdt', \n",
    "    'boost_from_average': False, \n",
    "    'objective': 'binary', \n",
    "    'tree_learner': 'serial', \n",
    "    'verbosity': 1,\n",
    "    'learning_rate': 0.01, \n",
    "    'num_threads': 22,\n",
    "    'metric':'auc',\n",
    "    \n",
    "    'num_leaves': 5, \n",
    "    'max_depth': 15,\n",
    "    'min_data_in_leaf': 150,\n",
    "    'min_sum_hessian_in_leaf': 10,\n",
    "    \n",
    "    'bagging_freq': 1,\n",
    "    'bagging_fraction': 0.6,\n",
    "    'feature_fraction': 0.05\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yVEBpoX_uT1J"
   },
   "outputs": [],
   "source": [
    "def train_lgbm(param, train_data, train_label, val_data, val_label):\n",
    "    print(\"===== Build dataset for lgbm\")\n",
    "    lgbm_train_data = lgb.Dataset(train_data, label=train_label)\n",
    "    lgbm_val_data = lgb.Dataset(val_data, label=val_label)\n",
    "    \n",
    "    print(\"===== Start training\")\n",
    "    start_time = time()\n",
    "    clf = lgb.train(param, \n",
    "                    lgbm_train_data, \n",
    "                    1000000, \n",
    "                    valid_sets = [lgbm_train_data, lgbm_val_data], \n",
    "                    verbose_eval = 1000, \n",
    "                    early_stopping_rounds = 3000)\n",
    "    training_time = (time() - start_time) / 60.\n",
    "    print(\"===== Training time: {:.2f}min\".format(training_time))\n",
    "    \n",
    "    # compute auroc\n",
    "    print(\"===== Get prediction\")\n",
    "    pred_tr = clf.predict(train_data, num_iteration=clf.best_iteration)\n",
    "    pred_cv = clf.predict(val_data, num_iteration=clf.best_iteration)\n",
    "    # get metrics\n",
    "    print(\"===== Build metrics\")\n",
    "    train_label, val_label = np.ravel(train_label), np.ravel(val_label)\n",
    "    a_tr = roc_auc_score(train_label, pred_tr)\n",
    "    a_cv = roc_auc_score(val_label, pred_cv)\n",
    "    progress = \"auroc|train {:.4f}|val {:.4f}\".format(a_tr, a_cv)\n",
    "    print(\"Final result\")\n",
    "    print(progress)\n",
    "    \n",
    "# without PCA\n",
    "# auroc|train 0.9830|val 0.9026\n",
    "# train_lgbm(param_base, train_data_aug, train_label_aug, val_data, val_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KQ7Ne9OnuT1K"
   },
   "outputs": [],
   "source": [
    "def dimension_reduction(train_data, val_data, n_components=200):\n",
    "    print(\"Train: {}\\nVal: {}\".format(train_data.shape, val_data.shape))\n",
    "    split_index = train_data.shape[0]\n",
    "    pca = PCA(n_components=n_components)\n",
    "    combined_data = pd.concat([train_data, val_data])\n",
    "    print(\"Combined: {}\".format(combined_data.shape))\n",
    "    combined_data_pca = pca.fit_transform(combined_data)\n",
    "    combined_data_pca = pd.DataFrame(combined_data_pca, columns = ['var_pca_{}'.format(i) for i in range(n_components)])\n",
    "    print(\"After PCA: {}\".format(combined_data_pca.shape))\n",
    "    train_data_pca = combined_data_pca[:split_index]\n",
    "    val_data_pca = combined_data_pca[split_index:]\n",
    "    print(\"Train: {}\\nVal: {}\".format(train_data_pca.shape, val_data_pca.shape))\n",
    "    return train_data_pca, val_data_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uAJbGmUVuT1M",
    "outputId": "cf147041-5808-4167-8512-6e69fa7dbdf1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (172159, 608)\n",
      "Val: (40000, 608)\n",
      "Combined: (212159, 608)\n",
      "After PCA: (212159, 300)\n",
      "Train: (172159, 300)\n",
      "Val: (40000, 300)\n"
     ]
    }
   ],
   "source": [
    "# round 1: dim = 300\n",
    "train_data_pca, val_data_pca = dimension_reduction(train_data, val_data, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rn6HEIg2uT1O",
    "outputId": "8781a55c-90c4-459c-9d9c-3411e8519239"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.946762\tvalid_1's auc: 0.776749\n",
      "[2000]\ttraining's auc: 0.95646\tvalid_1's auc: 0.811801\n",
      "[3000]\ttraining's auc: 0.960945\tvalid_1's auc: 0.827428\n",
      "[4000]\ttraining's auc: 0.963768\tvalid_1's auc: 0.836371\n",
      "[5000]\ttraining's auc: 0.965776\tvalid_1's auc: 0.842404\n",
      "[6000]\ttraining's auc: 0.967317\tvalid_1's auc: 0.846597\n",
      "[7000]\ttraining's auc: 0.968545\tvalid_1's auc: 0.849658\n",
      "[8000]\ttraining's auc: 0.969533\tvalid_1's auc: 0.851772\n",
      "[9000]\ttraining's auc: 0.970381\tvalid_1's auc: 0.853485\n",
      "[10000]\ttraining's auc: 0.971168\tvalid_1's auc: 0.85475\n",
      "[11000]\ttraining's auc: 0.971894\tvalid_1's auc: 0.855725\n",
      "[12000]\ttraining's auc: 0.972551\tvalid_1's auc: 0.856444\n",
      "[13000]\ttraining's auc: 0.973167\tvalid_1's auc: 0.857041\n",
      "[14000]\ttraining's auc: 0.97377\tvalid_1's auc: 0.857619\n",
      "[15000]\ttraining's auc: 0.974365\tvalid_1's auc: 0.857891\n",
      "[16000]\ttraining's auc: 0.974931\tvalid_1's auc: 0.858152\n",
      "[17000]\ttraining's auc: 0.975485\tvalid_1's auc: 0.858328\n",
      "[18000]\ttraining's auc: 0.976032\tvalid_1's auc: 0.858613\n",
      "[19000]\ttraining's auc: 0.976558\tvalid_1's auc: 0.858709\n",
      "[20000]\ttraining's auc: 0.977071\tvalid_1's auc: 0.858845\n",
      "[21000]\ttraining's auc: 0.977572\tvalid_1's auc: 0.858952\n",
      "[22000]\ttraining's auc: 0.978055\tvalid_1's auc: 0.859006\n",
      "[23000]\ttraining's auc: 0.978545\tvalid_1's auc: 0.859036\n",
      "[24000]\ttraining's auc: 0.97903\tvalid_1's auc: 0.859106\n",
      "[25000]\ttraining's auc: 0.979502\tvalid_1's auc: 0.85912\n",
      "[26000]\ttraining's auc: 0.979954\tvalid_1's auc: 0.859151\n",
      "[27000]\ttraining's auc: 0.980404\tvalid_1's auc: 0.859119\n",
      "[28000]\ttraining's auc: 0.980842\tvalid_1's auc: 0.859185\n",
      "[29000]\ttraining's auc: 0.981273\tvalid_1's auc: 0.859061\n",
      "[30000]\ttraining's auc: 0.981698\tvalid_1's auc: 0.859067\n",
      "[31000]\ttraining's auc: 0.982114\tvalid_1's auc: 0.859003\n",
      "Early stopping, best iteration is:\n",
      "[28090]\ttraining's auc: 0.980881\tvalid_1's auc: 0.859204\n",
      "===== Training time: 3.99min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9809|val 0.8592\n"
     ]
    }
   ],
   "source": [
    "train_lgbm(param_base, train_data_pca, train_label, val_data_pca, val_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y-8WKFCyuT1Q",
    "outputId": "f622728e-c1cf-4819-abb3-32224a5d6a05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (172159, 608)\n",
      "Val: (40000, 608)\n",
      "Combined: (212159, 608)\n",
      "After PCA: (212159, 200)\n",
      "Train: (172159, 200)\n",
      "Val: (40000, 200)\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.945249\tvalid_1's auc: 0.770803\n",
      "[2000]\ttraining's auc: 0.954326\tvalid_1's auc: 0.802697\n",
      "[3000]\ttraining's auc: 0.958504\tvalid_1's auc: 0.817061\n",
      "[4000]\ttraining's auc: 0.961215\tvalid_1's auc: 0.825547\n",
      "[5000]\ttraining's auc: 0.963143\tvalid_1's auc: 0.831152\n",
      "[6000]\ttraining's auc: 0.964644\tvalid_1's auc: 0.835423\n",
      "[7000]\ttraining's auc: 0.965828\tvalid_1's auc: 0.838282\n",
      "[8000]\ttraining's auc: 0.966799\tvalid_1's auc: 0.840429\n",
      "[9000]\ttraining's auc: 0.967598\tvalid_1's auc: 0.841971\n",
      "[10000]\ttraining's auc: 0.96833\tvalid_1's auc: 0.843103\n",
      "[11000]\ttraining's auc: 0.969014\tvalid_1's auc: 0.843932\n",
      "[12000]\ttraining's auc: 0.969671\tvalid_1's auc: 0.844588\n",
      "[13000]\ttraining's auc: 0.970287\tvalid_1's auc: 0.845157\n",
      "[14000]\ttraining's auc: 0.970892\tvalid_1's auc: 0.845609\n",
      "[15000]\ttraining's auc: 0.971455\tvalid_1's auc: 0.845905\n",
      "[16000]\ttraining's auc: 0.97202\tvalid_1's auc: 0.846109\n",
      "[17000]\ttraining's auc: 0.972549\tvalid_1's auc: 0.846429\n",
      "[18000]\ttraining's auc: 0.973085\tvalid_1's auc: 0.846556\n",
      "[19000]\ttraining's auc: 0.973612\tvalid_1's auc: 0.846718\n",
      "[20000]\ttraining's auc: 0.974115\tvalid_1's auc: 0.846865\n",
      "[21000]\ttraining's auc: 0.974618\tvalid_1's auc: 0.846825\n",
      "[22000]\ttraining's auc: 0.975098\tvalid_1's auc: 0.846932\n",
      "[23000]\ttraining's auc: 0.975577\tvalid_1's auc: 0.847002\n",
      "[24000]\ttraining's auc: 0.976051\tvalid_1's auc: 0.847084\n",
      "[25000]\ttraining's auc: 0.976523\tvalid_1's auc: 0.847046\n",
      "[26000]\ttraining's auc: 0.976984\tvalid_1's auc: 0.847158\n",
      "[27000]\ttraining's auc: 0.977446\tvalid_1's auc: 0.84716\n",
      "[28000]\ttraining's auc: 0.977891\tvalid_1's auc: 0.847134\n",
      "[29000]\ttraining's auc: 0.978334\tvalid_1's auc: 0.847132\n",
      "[30000]\ttraining's auc: 0.978773\tvalid_1's auc: 0.84713\n",
      "Early stopping, best iteration is:\n",
      "[27396]\ttraining's auc: 0.977622\tvalid_1's auc: 0.847254\n",
      "===== Training time: 3.69min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9776|val 0.8473\n"
     ]
    }
   ],
   "source": [
    "# round 2: dim = 200\n",
    "train_data_pca, val_data_pca = dimension_reduction(train_data, val_data, 200)\n",
    "train_lgbm(param_base, train_data_pca, train_label, val_data_pca, val_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vnx1tWBduT1R",
    "outputId": "7af1c76a-d40d-42af-9f67-71cc5ea19416"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (172159, 608)\n",
      "Val: (40000, 608)\n",
      "Combined: (212159, 608)\n",
      "After PCA: (212159, 150)\n",
      "Train: (172159, 150)\n",
      "Val: (40000, 150)\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.941165\tvalid_1's auc: 0.751078\n",
      "[2000]\ttraining's auc: 0.951436\tvalid_1's auc: 0.788309\n",
      "[3000]\ttraining's auc: 0.955301\tvalid_1's auc: 0.8013\n",
      "[4000]\ttraining's auc: 0.957711\tvalid_1's auc: 0.808902\n",
      "[5000]\ttraining's auc: 0.959476\tvalid_1's auc: 0.813995\n",
      "[6000]\ttraining's auc: 0.960874\tvalid_1's auc: 0.817785\n",
      "[7000]\ttraining's auc: 0.961999\tvalid_1's auc: 0.820328\n",
      "[8000]\ttraining's auc: 0.962955\tvalid_1's auc: 0.822261\n",
      "[9000]\ttraining's auc: 0.963776\tvalid_1's auc: 0.823688\n",
      "[10000]\ttraining's auc: 0.96451\tvalid_1's auc: 0.824833\n",
      "[11000]\ttraining's auc: 0.965181\tvalid_1's auc: 0.825603\n",
      "[12000]\ttraining's auc: 0.96583\tvalid_1's auc: 0.826178\n",
      "[13000]\ttraining's auc: 0.966437\tvalid_1's auc: 0.826692\n",
      "[14000]\ttraining's auc: 0.967032\tvalid_1's auc: 0.827112\n",
      "[15000]\ttraining's auc: 0.967615\tvalid_1's auc: 0.827553\n",
      "[16000]\ttraining's auc: 0.968165\tvalid_1's auc: 0.827827\n",
      "[17000]\ttraining's auc: 0.968713\tvalid_1's auc: 0.828068\n",
      "[18000]\ttraining's auc: 0.969259\tvalid_1's auc: 0.828264\n",
      "[19000]\ttraining's auc: 0.969787\tvalid_1's auc: 0.828455\n",
      "[20000]\ttraining's auc: 0.970307\tvalid_1's auc: 0.828597\n",
      "[21000]\ttraining's auc: 0.970813\tvalid_1's auc: 0.828705\n",
      "[22000]\ttraining's auc: 0.971322\tvalid_1's auc: 0.828831\n",
      "[23000]\ttraining's auc: 0.971822\tvalid_1's auc: 0.828846\n",
      "[24000]\ttraining's auc: 0.972312\tvalid_1's auc: 0.828943\n",
      "[25000]\ttraining's auc: 0.972789\tvalid_1's auc: 0.828941\n",
      "[26000]\ttraining's auc: 0.973278\tvalid_1's auc: 0.828985\n",
      "[27000]\ttraining's auc: 0.973746\tvalid_1's auc: 0.829003\n",
      "[28000]\ttraining's auc: 0.974206\tvalid_1's auc: 0.828996\n",
      "[29000]\ttraining's auc: 0.974657\tvalid_1's auc: 0.828984\n",
      "[30000]\ttraining's auc: 0.975103\tvalid_1's auc: 0.828984\n",
      "Early stopping, best iteration is:\n",
      "[27678]\ttraining's auc: 0.974059\tvalid_1's auc: 0.829045\n",
      "===== Training time: 3.87min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9741|val 0.8290\n"
     ]
    }
   ],
   "source": [
    "# round 3: dim = 150\n",
    "train_data_pca, val_data_pca = dimension_reduction(train_data, val_data, 150)\n",
    "train_lgbm(param_base, train_data_pca, train_label, val_data_pca, val_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4NWItBkPuT1T",
    "outputId": "40bf2e66-e9e8-4281-ecdd-bb6c30309cac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (172159, 608)\n",
      "Val: (40000, 608)\n",
      "Combined: (212159, 608)\n",
      "After PCA: (212159, 100)\n",
      "Train: (172159, 100)\n",
      "Val: (40000, 100)\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.915639\tvalid_1's auc: 0.6503\n",
      "[2000]\ttraining's auc: 0.929271\tvalid_1's auc: 0.699622\n",
      "[3000]\ttraining's auc: 0.939095\tvalid_1's auc: 0.736353\n",
      "[4000]\ttraining's auc: 0.944588\tvalid_1's auc: 0.756413\n",
      "[5000]\ttraining's auc: 0.947958\tvalid_1's auc: 0.768363\n",
      "[6000]\ttraining's auc: 0.950179\tvalid_1's auc: 0.775534\n",
      "[7000]\ttraining's auc: 0.95188\tvalid_1's auc: 0.780546\n",
      "[8000]\ttraining's auc: 0.953222\tvalid_1's auc: 0.784051\n",
      "[9000]\ttraining's auc: 0.954347\tvalid_1's auc: 0.786538\n",
      "[10000]\ttraining's auc: 0.955344\tvalid_1's auc: 0.788561\n",
      "[11000]\ttraining's auc: 0.956232\tvalid_1's auc: 0.790089\n",
      "[12000]\ttraining's auc: 0.957058\tvalid_1's auc: 0.791336\n",
      "[13000]\ttraining's auc: 0.957814\tvalid_1's auc: 0.792258\n",
      "[14000]\ttraining's auc: 0.958521\tvalid_1's auc: 0.792975\n",
      "[15000]\ttraining's auc: 0.959215\tvalid_1's auc: 0.793418\n",
      "[16000]\ttraining's auc: 0.959898\tvalid_1's auc: 0.793834\n",
      "[17000]\ttraining's auc: 0.960552\tvalid_1's auc: 0.794234\n",
      "[18000]\ttraining's auc: 0.96118\tvalid_1's auc: 0.794423\n",
      "[19000]\ttraining's auc: 0.961789\tvalid_1's auc: 0.794612\n",
      "[20000]\ttraining's auc: 0.962386\tvalid_1's auc: 0.79474\n",
      "[21000]\ttraining's auc: 0.962988\tvalid_1's auc: 0.794918\n",
      "[22000]\ttraining's auc: 0.963586\tvalid_1's auc: 0.795112\n",
      "[23000]\ttraining's auc: 0.96417\tvalid_1's auc: 0.795174\n",
      "[24000]\ttraining's auc: 0.964743\tvalid_1's auc: 0.795234\n",
      "[25000]\ttraining's auc: 0.965329\tvalid_1's auc: 0.795207\n",
      "[26000]\ttraining's auc: 0.965871\tvalid_1's auc: 0.795247\n",
      "[27000]\ttraining's auc: 0.966412\tvalid_1's auc: 0.795221\n",
      "[28000]\ttraining's auc: 0.966956\tvalid_1's auc: 0.795229\n",
      "[29000]\ttraining's auc: 0.967493\tvalid_1's auc: 0.795169\n",
      "Early stopping, best iteration is:\n",
      "[26436]\ttraining's auc: 0.966106\tvalid_1's auc: 0.795293\n",
      "===== Training time: 3.63min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9661|val 0.7953\n"
     ]
    }
   ],
   "source": [
    "# round 3: dim = 100\n",
    "train_data_pca, val_data_pca = dimension_reduction(train_data, val_data, 100)\n",
    "train_lgbm(param_base, train_data_pca, train_label, val_data_pca, val_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "00D0uBlzuT1V",
    "outputId": "756aa1fd-90de-44f8-8974-7483717e7f7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (172159, 608)\n",
      "Val: (40000, 608)\n",
      "Combined: (212159, 608)\n",
      "After PCA: (212159, 80)\n",
      "Train: (172159, 80)\n",
      "Val: (40000, 80)\n",
      "===== Build dataset for lgbm\n",
      "===== Start training\n",
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.909063\tvalid_1's auc: 0.627087\n",
      "[2000]\ttraining's auc: 0.921082\tvalid_1's auc: 0.671811\n",
      "[3000]\ttraining's auc: 0.930211\tvalid_1's auc: 0.704858\n",
      "[4000]\ttraining's auc: 0.935837\tvalid_1's auc: 0.725037\n",
      "[5000]\ttraining's auc: 0.939495\tvalid_1's auc: 0.737437\n",
      "[6000]\ttraining's auc: 0.942029\tvalid_1's auc: 0.74524\n",
      "[7000]\ttraining's auc: 0.943959\tvalid_1's auc: 0.750695\n",
      "[8000]\ttraining's auc: 0.94553\tvalid_1's auc: 0.754671\n",
      "[9000]\ttraining's auc: 0.946841\tvalid_1's auc: 0.757686\n",
      "[10000]\ttraining's auc: 0.947971\tvalid_1's auc: 0.760079\n",
      "[11000]\ttraining's auc: 0.948947\tvalid_1's auc: 0.761897\n",
      "[12000]\ttraining's auc: 0.949864\tvalid_1's auc: 0.763181\n",
      "[13000]\ttraining's auc: 0.950706\tvalid_1's auc: 0.764125\n",
      "[14000]\ttraining's auc: 0.951516\tvalid_1's auc: 0.764907\n",
      "[15000]\ttraining's auc: 0.952281\tvalid_1's auc: 0.765447\n",
      "[16000]\ttraining's auc: 0.952999\tvalid_1's auc: 0.765856\n",
      "[17000]\ttraining's auc: 0.953681\tvalid_1's auc: 0.76625\n",
      "[18000]\ttraining's auc: 0.954364\tvalid_1's auc: 0.766448\n",
      "[19000]\ttraining's auc: 0.955017\tvalid_1's auc: 0.766645\n",
      "[20000]\ttraining's auc: 0.955659\tvalid_1's auc: 0.766739\n",
      "[21000]\ttraining's auc: 0.956289\tvalid_1's auc: 0.766805\n",
      "[22000]\ttraining's auc: 0.956891\tvalid_1's auc: 0.766813\n",
      "[23000]\ttraining's auc: 0.957499\tvalid_1's auc: 0.76688\n",
      "[24000]\ttraining's auc: 0.958097\tvalid_1's auc: 0.766855\n",
      "[25000]\ttraining's auc: 0.95868\tvalid_1's auc: 0.766817\n",
      "Early stopping, best iteration is:\n",
      "[22840]\ttraining's auc: 0.957401\tvalid_1's auc: 0.766955\n",
      "===== Training time: 3.28min\n",
      "===== Get prediction\n",
      "===== Build metrics\n",
      "Final result\n",
      "auroc|train 0.9574|val 0.7670\n"
     ]
    }
   ],
   "source": [
    "# round 3: dim = 80\n",
    "train_data_pca, val_data_pca = dimension_reduction(train_data, val_data, 80)\n",
    "train_lgbm(param_base, train_data_pca, train_label, val_data_pca, val_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_pVCHRscuT1X"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8VE8LXqIuT1Y"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "010_run_lgbm_on_PCA.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
